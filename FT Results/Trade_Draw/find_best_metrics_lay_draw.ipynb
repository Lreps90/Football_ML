{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T12:44:15.865104Z",
     "start_time": "2025-09-07T12:44:15.828239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# ========= Settings =========\n",
    "BASE = r\"C:\\Users\\leere\\PycharmProjects\\Football_ML3\\FT Results\"\n",
    "MARKETS = [\"Lay_Home\", \"Lay_Away\", \"Lay_Draw\", \"Back_Home\", \"Back_Away\", \"Back_Draw\"]\n",
    "\n",
    "# Safety: keep True while testing (will only print what would be deleted)\n",
    "DRY_RUN_PKLS = True\n",
    "\n",
    "# ========= Helpers =========\n",
    "def metrics_dir(market: str) -> str:\n",
    "    return os.path.join(BASE, market, \"best_model_metrics\")\n",
    "\n",
    "def model_dir(market: str) -> str:\n",
    "    return os.path.join(BASE, market, \"model_file\")\n",
    "\n",
    "def is_failed_filename(path: str) -> bool:\n",
    "    base = os.path.basename(path)\n",
    "    name_no_ext, _ = os.path.splitext(base)\n",
    "    return base.endswith(\"_FAILED\") or base.endswith(\"_FAILED.csv\") or name_no_ext.endswith(\"_FAILED\")\n",
    "\n",
    "def read_csv_safely(path: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        return pd.read_csv(path, low_memory=False)\n",
    "    except Exception as e:\n",
    "        print(f\"  [WARN] Failed to read {path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def deduplicate_sorted(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    After sorting by val_precision_lcb desc, drop duplicates on logical 'candidate' keys.\n",
    "    \"\"\"\n",
    "    XGB = [\"n_estimators\",\"max_depth\",\"learning_rate\",\"min_child_weight\",\"subsample\",\"colsample_bytree\",\"reg_lambda\"]\n",
    "    MLP = [\"hidden_layer_sizes\",\"alpha\",\"learning_rate_init\",\"batch_size\",\"max_iter\"]\n",
    "    key_cols = [c for c in ([\"threshold\"] + XGB + MLP) if c in df.columns]\n",
    "    if key_cols:\n",
    "        return df.drop_duplicates(subset=key_cols, keep=\"first\").reset_index(drop=True)\n",
    "    return df.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "def normalise_model_path(p: str) -> str | None:\n",
    "    if not isinstance(p, str) or not p.strip():\n",
    "        return None\n",
    "    p = p.strip().strip('\"').strip(\"'\")\n",
    "    try:\n",
    "        return os.path.realpath(p)\n",
    "    except Exception:\n",
    "        return os.path.abspath(p)\n",
    "\n",
    "def choose_best_model_path(df: pd.DataFrame) -> str | None:\n",
    "    if \"model_pkl\" not in df.columns:\n",
    "        print(\"  [WARN] 'model_pkl' column not in CSVs; cannot pick a model to keep.\")\n",
    "        return None\n",
    "    for _, row in df.iterrows():\n",
    "        raw = (row.get(\"model_pkl\") or \"\").strip()\n",
    "        if raw:\n",
    "            p = normalise_model_path(raw)\n",
    "            if p:\n",
    "                return p\n",
    "    print(\"  [WARN] No non-empty 'model_pkl' found in combined CSV.\")\n",
    "    return None\n",
    "\n",
    "def prune_pkls_keep_one(folder: str, keep_path: str | None) -> None:\n",
    "    print(\"— Pruning model_file directory —\")\n",
    "    if not os.path.isdir(folder):\n",
    "        print(f\"  [WARN] model folder does not exist: {folder}\")\n",
    "        return\n",
    "\n",
    "    all_pkls = []\n",
    "    for name in os.listdir(folder):\n",
    "        p = os.path.join(folder, name)\n",
    "        if os.path.isfile(p) and name.lower().endswith(\".pkl\"):\n",
    "            all_pkls.append(os.path.realpath(p))\n",
    "\n",
    "    keep_real = os.path.realpath(keep_path) if keep_path else None\n",
    "    to_delete = sorted([p for p in all_pkls if p != keep_real])\n",
    "\n",
    "    print(f\"  Found .pkl files: {len(all_pkls)}\")\n",
    "    print(f\"  Keeping: {keep_real if keep_real else '(none)'}\")\n",
    "    print(f\"  Will delete: {len(to_delete)}\")\n",
    "\n",
    "    if DRY_RUN_PKLS:\n",
    "        for p in to_delete[:20]:\n",
    "            print(f\"    (dry-run) would delete: {p}\")\n",
    "        if len(to_delete) > 20:\n",
    "            print(f\"    ...and {len(to_delete) - 20} more.\")\n",
    "        print(\"  Set DRY_RUN_PKLS = False to actually delete.\")\n",
    "        return\n",
    "\n",
    "    for p in to_delete:\n",
    "        try:\n",
    "            os.remove(p)\n",
    "            print(f\"   ✂ Deleted: {p}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   [WARN] Could not delete {p}: {e}\")\n",
    "\n",
    "def collect_csvs(mdir: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Collect run CSVs and any existing COMBINED CSVs in the metrics folder.\n",
    "    Excludes *_FAILED*.csv\n",
    "    \"\"\"\n",
    "    patterns = [\n",
    "        os.path.join(mdir, \"model_metrics_*.csv\"),\n",
    "        os.path.join(mdir, \"model_metrics_*COMBINED_*.csv\"),\n",
    "    ]\n",
    "    out = []\n",
    "    for pat in patterns:\n",
    "        for p in glob.glob(pat):\n",
    "            if not is_failed_filename(p):\n",
    "                out.append(p)\n",
    "    # Deduplicate by realpath\n",
    "    seen, uniq = set(), []\n",
    "    for p in out:\n",
    "        rp = os.path.realpath(p)\n",
    "        if rp not in seen:\n",
    "            seen.add(rp)\n",
    "            uniq.append(rp)\n",
    "    return sorted(uniq)\n",
    "\n",
    "def merge_and_rank_for_market(market: str) -> None:\n",
    "    mdir = metrics_dir(market)\n",
    "    pdir = model_dir(market)\n",
    "    os.makedirs(mdir, exist_ok=True)\n",
    "    os.makedirs(pdir, exist_ok=True)\n",
    "\n",
    "    print(f\"\\n===== {market} =====\")\n",
    "    print(f\" Metrics dir: {mdir}\")\n",
    "    print(f\" Model dir:   {pdir}\")\n",
    "\n",
    "    csv_paths = collect_csvs(mdir)\n",
    "    if not csv_paths:\n",
    "        print(\"  No CSVs found to merge; skipping.\")\n",
    "        return\n",
    "\n",
    "    frames, used = [], []\n",
    "    for p in csv_paths:\n",
    "        df = read_csv_safely(p)\n",
    "        if df.empty:\n",
    "            print(f\"  [WARN] Empty/unreadable CSV skipped: {p}\")\n",
    "            continue\n",
    "        frames.append(df)\n",
    "        used.append(p)\n",
    "\n",
    "    if not frames:\n",
    "        print(\"  No usable CSV data; skipping.\")\n",
    "        return\n",
    "\n",
    "    combined = pd.concat(frames, ignore_index=True, sort=False)\n",
    "\n",
    "    if \"val_precision_lcb\" not in combined.columns:\n",
    "        print(\"  [WARN] 'val_precision_lcb' missing; cannot rank. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # rank\n",
    "    combined[\"val_precision_lcb\"] = pd.to_numeric(combined[\"val_precision_lcb\"], errors=\"coerce\")\n",
    "    combined = combined.dropna(subset=[\"val_precision_lcb\"]).reset_index(drop=True)\n",
    "    if combined.empty:\n",
    "        print(\"  No rows with numeric 'val_precision_lcb'; skipping.\")\n",
    "        return\n",
    "\n",
    "    combined = combined.sort_values(by=[\"val_precision_lcb\"], ascending=False, kind=\"mergesort\").reset_index(drop=True)\n",
    "    combined = deduplicate_sorted(combined)\n",
    "\n",
    "    # write combined\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_path = os.path.join(mdir, f\"model_metrics_COMBINED_{ts}.csv\")\n",
    "    combined.to_csv(out_path, index=False)\n",
    "    print(f\"  ✓ Wrote COMBINED CSV ({len(combined)} rows): {out_path}\")\n",
    "\n",
    "    # delete inputs used for this merge (both runs and older COMBINEDs)\n",
    "    deleted, failed = 0, 0\n",
    "    for p in used:\n",
    "        try:\n",
    "            if os.path.exists(p) and p != out_path:\n",
    "                os.remove(p)\n",
    "                deleted += 1\n",
    "                print(f\"   ✂ Deleted merged input CSV: {p}\")\n",
    "        except Exception as e:\n",
    "            failed += 1\n",
    "            print(f\"   [WARN] Could not delete CSV {p}: {e}\")\n",
    "    if deleted or failed:\n",
    "        print(f\"  Input CSV cleanup — deleted: {deleted}, failed: {failed}\")\n",
    "\n",
    "    # keep only the top model's PKL\n",
    "    best_model = choose_best_model_path(combined)\n",
    "    if best_model and not os.path.exists(best_model):\n",
    "        print(f\"  [WARN] Best model path does not exist on disk (keeping path anyway): {best_model}\")\n",
    "    prune_pkls_keep_one(pdir, best_model)\n",
    "\n",
    "def main():\n",
    "    for m in MARKETS:\n",
    "        merge_and_rank_for_market(m)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "6ef8ffd7abe975ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Lay_Home =====\n",
      " Metrics dir: C:\\Users\\leere\\PycharmProjects\\Football_ML3\\FT Results\\Lay_Home\\best_model_metrics\n",
      " Model dir:   C:\\Users\\leere\\PycharmProjects\\Football_ML3\\FT Results\\Lay_Home\\model_file\n",
      "  No CSVs found to merge; skipping.\n",
      "\n",
      "===== Lay_Away =====\n",
      " Metrics dir: C:\\Users\\leere\\PycharmProjects\\Football_ML3\\FT Results\\Lay_Away\\best_model_metrics\n",
      " Model dir:   C:\\Users\\leere\\PycharmProjects\\Football_ML3\\FT Results\\Lay_Away\\model_file\n",
      "  ✓ Wrote COMBINED CSV (13 rows): C:\\Users\\leere\\PycharmProjects\\Football_ML3\\FT Results\\Lay_Away\\best_model_metrics\\model_metrics_COMBINED_20250907_134415.csv\n",
      "   ✂ Deleted merged input CSV: C:\\Users\\leere\\PycharmProjects\\Football_ML3\\FT Results\\Lay_Away\\best_model_metrics\\model_metrics_LAY_AWAY_20250907_132958.csv\n",
      "   ✂ Deleted merged input CSV: C:\\Users\\leere\\PycharmProjects\\Football_ML3\\FT Results\\Lay_Away\\best_model_metrics\\model_metrics_LAY_AWAY_20250907_133926.csv\n",
      "  Input CSV cleanup — deleted: 2, failed: 0\n",
      "  [WARN] Best model path does not exist on disk (keeping path anyway): C:\\Users\\leere\\PycharmProjects\\Football_ML3\\MatchOdds\\Lay_Away\\model_file\\best_model_LAY_AWAY_xgb_calibrated_20250907_132958.pkl\n",
      "— Pruning model_file directory —\n",
      "  Found .pkl files: 2\n",
      "  Keeping: C:\\Users\\leere\\PycharmProjects\\Football_ML3\\MatchOdds\\Lay_Away\\model_file\\best_model_LAY_AWAY_xgb_calibrated_20250907_132958.pkl\n",
      "  Will delete: 2\n",
      "    (dry-run) would delete: C:\\Users\\leere\\PycharmProjects\\Football_ML3\\FT Results\\Lay_Away\\model_file\\best_model_LAY_AWAY_xgb_calibrated_20250907_132958.pkl\n",
      "    (dry-run) would delete: C:\\Users\\leere\\PycharmProjects\\Football_ML3\\FT Results\\Lay_Away\\model_file\\best_model_LAY_AWAY_xgb_calibrated_20250907_133926.pkl\n",
      "  Set DRY_RUN_PKLS = False to actually delete.\n",
      "\n",
      "===== Lay_Draw =====\n",
      " Metrics dir: C:\\Users\\leere\\PycharmProjects\\Football_ML3\\FT Results\\Lay_Draw\\best_model_metrics\n",
      " Model dir:   C:\\Users\\leere\\PycharmProjects\\Football_ML3\\FT Results\\Lay_Draw\\model_file\n",
      "  No CSVs found to merge; skipping.\n",
      "\n",
      "===== Back_Home =====\n",
      " Metrics dir: C:\\Users\\leere\\PycharmProjects\\Football_ML3\\FT Results\\Back_Home\\best_model_metrics\n",
      " Model dir:   C:\\Users\\leere\\PycharmProjects\\Football_ML3\\FT Results\\Back_Home\\model_file\n",
      "  No CSVs found to merge; skipping.\n",
      "\n",
      "===== Back_Away =====\n",
      " Metrics dir: C:\\Users\\leere\\PycharmProjects\\Football_ML3\\FT Results\\Back_Away\\best_model_metrics\n",
      " Model dir:   C:\\Users\\leere\\PycharmProjects\\Football_ML3\\FT Results\\Back_Away\\model_file\n",
      "  No CSVs found to merge; skipping.\n",
      "\n",
      "===== Back_Draw =====\n",
      " Metrics dir: C:\\Users\\leere\\PycharmProjects\\Football_ML3\\FT Results\\Back_Draw\\best_model_metrics\n",
      " Model dir:   C:\\Users\\leere\\PycharmProjects\\Football_ML3\\FT Results\\Back_Draw\\model_file\n",
      "  No CSVs found to merge; skipping.\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
