{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-17T11:28:00.869517Z",
     "start_time": "2025-04-17T11:27:57.168739Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import function_library as fl\n",
    "from datetime import datetime\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:30:47.702406Z",
     "start_time": "2025-04-17T11:30:08.584219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "def sort_files_by_precision(directory: str, inplace: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Reads all CSV files in `directory`, sorts each by the 'Precision_Test' column\n",
    "    in descending order, and writes the sorted DataFrame back.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the folder containing CSVs.\n",
    "        inplace (bool):\n",
    "            - If True, overwrite each original file.\n",
    "            - If False, write to new files prefixed with 'sorted_'.\n",
    "    \"\"\"\n",
    "    pattern = os.path.join(directory, \"*.csv\")\n",
    "    for filepath in glob.glob(pattern):\n",
    "        df = pd.read_csv(filepath)\n",
    "        if 'Precision_Test' not in df.columns:\n",
    "            print(f\"Skipping {os.path.basename(filepath)}: no 'Precision_Test' column\")\n",
    "            continue\n",
    "\n",
    "        # sort so highest Precision_Test is at the top\n",
    "        df_sorted = df.sort_values(by='Precision_Test', ascending=False)\n",
    "\n",
    "        if inplace:\n",
    "            df_sorted.to_csv(filepath, index=False)\n",
    "            print(f\"✔ Sorted (in‐place): {os.path.basename(filepath)}\")\n",
    "        else:\n",
    "            dirname, filename = os.path.split(filepath)\n",
    "            new_filename = f\"sorted_{filename}\"\n",
    "            df_sorted.to_csv(os.path.join(dirname, new_filename), index=False)\n",
    "            print(f\"✔ Written sorted file: {new_filename}\")\n",
    "\n",
    "directory = r\"C:\\Users\\leere\\PycharmProjects\\Football_ML3\\Goals\\2H_goal\\best_models_by_ht_scoreline\"\n",
    "sort_files_by_precision(directory, inplace=True)\n"
   ],
   "id": "cdf062636a7bcb43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Sorted (in‐place): model_metrics_('0-0',)_20250413_143631.csv\n",
      "✔ Sorted (in‐place): model_metrics_('0-1',)_20250414_235442.csv\n",
      "✔ Sorted (in‐place): model_metrics_('0-2',)_20250416_123947.csv\n",
      "✔ Sorted (in‐place): model_metrics_('1-0',)_20250414_114908.csv\n",
      "✔ Sorted (in‐place): model_metrics_('1-1',)_20250415_075613.csv\n",
      "✔ Sorted (in‐place): model_metrics_('1-2',)_20250415_113409.csv\n",
      "✔ Sorted (in‐place): model_metrics_('2-0',)_20250415_212648.csv\n",
      "✔ Sorted (in‐place): model_metrics_('2-1',)_20250416_190132.csv\n",
      "✔ Sorted (in‐place): model_metrics_('3-0',)_20250415_142122.csv\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:37:05.484121Z",
     "start_time": "2025-04-17T11:36:58.849394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Directory containing the CSV files\n",
    "directory = r\"C:\\Users\\leere\\PycharmProjects\\Football_ML3\\Goals\\2H_goal\\best_models_by_ht_scoreline\"\n",
    "\n",
    "# List to collect each top row's data\n",
    "top_rows = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith(\"model_metrics_(\") and filename.endswith(\".csv\"):\n",
    "        ht_score = filename.split(\"_\")[2]  # Extract league name from filename\n",
    "        file_path = os.path.join(directory, filename)\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            top_row = df.iloc[0]  # Get only the first row\n",
    "            top_rows.append({\n",
    "                'HT_Score': ht_score,\n",
    "                'Model': top_row['Model'],\n",
    "                'SMOTE': top_row.get('SMOTE'),\n",
    "                'Precision_Test': top_row.get('Precision_Test'),\n",
    "                'Precision_Test/Train_Ratio': top_row.get('Precision_Test/Train_Ratio'),\n",
    "                'Probability_Threshold': top_row.get('Probability_Threshold'),\n",
    "                'Params': top_row.get('Params')\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "# Combine all results into one DataFrame\n",
    "results_df = pd.DataFrame(top_rows)\n",
    "\n",
    "# Save or display results\n",
    "#results_df.to_csv(\"top_row_model_params.csv\", index=False)\n",
    "\n"
   ],
   "id": "fce1a11317aadeba",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:37:05.505527Z",
     "start_time": "2025-04-17T11:37:05.494693Z"
    }
   },
   "cell_type": "code",
   "source": "results_df",
   "id": "4d8e688853c111c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   HT_Score    Model  SMOTE  Precision_Test  Precision_Test/Train_Ratio  \\\n",
       "0  ('0-0',)  XGBoost    NaN          0.8641                      0.9350   \n",
       "1  ('0-1',)  XGBoost   0.62          0.8711                      0.9283   \n",
       "2  ('0-2',)      MLP    NaN          0.8475                      0.9745   \n",
       "3  ('1-0',)  XGBoost   0.63          0.8791                      0.9422   \n",
       "4  ('1-1',)  XGBoost    NaN          0.9028                      0.9166   \n",
       "5  ('1-2',)  XGBoost   0.90          0.8564                      0.9653   \n",
       "6  ('2-0',)  XGBoost   0.41          0.9268                      0.9914   \n",
       "7  ('2-1',)  XGBoost   0.47          0.9028                      0.9053   \n",
       "8  ('3-0',)  XGBoost   0.73          0.8700                      0.9321   \n",
       "\n",
       "   Probability_Threshold                                             Params  \n",
       "0                   0.80  {'classifier__colsample_bytree': 0.7, 'classif...  \n",
       "1                   0.81  {'classifier__colsample_bytree': 0.8, 'classif...  \n",
       "2                   0.81  {'classifier__activation': 'relu', 'classifier...  \n",
       "3                   0.81  {'classifier__colsample_bytree': 0.8, 'classif...  \n",
       "4                   0.81  {'classifier__colsample_bytree': 0.7, 'classif...  \n",
       "5                   0.60  {'classifier__colsample_bytree': 0.7, 'classif...  \n",
       "6                   0.76  {'classifier__colsample_bytree': 0.8, 'classif...  \n",
       "7                   0.80  {'classifier__colsample_bytree': 0.7, 'classif...  \n",
       "8                   0.65  {'classifier__colsample_bytree': 0.8, 'classif...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HT_Score</th>\n",
       "      <th>Model</th>\n",
       "      <th>SMOTE</th>\n",
       "      <th>Precision_Test</th>\n",
       "      <th>Precision_Test/Train_Ratio</th>\n",
       "      <th>Probability_Threshold</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('0-0',)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8641</td>\n",
       "      <td>0.9350</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.7, 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('0-1',)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.8711</td>\n",
       "      <td>0.9283</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('0-2',)</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8475</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('1-0',)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.8791</td>\n",
       "      <td>0.9422</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('1-1',)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9166</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.7, 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>('1-2',)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.8564</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>0.60</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.7, 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>('2-0',)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.9268</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.76</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>('2-1',)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.7, 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>('3-0',)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.8700</td>\n",
       "      <td>0.9321</td>\n",
       "      <td>0.65</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:37:09.843275Z",
     "start_time": "2025-04-17T11:37:09.833775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features = [\n",
    "    # 'Unnamed: 0',\n",
    "    # 'country',\n",
    "    # 'season',\n",
    "    # 'date',\n",
    "    # 'ko_time',\n",
    "    'round',\n",
    "    # 'home_team',\n",
    "    # 'away_team',\n",
    "    # 'home_goals_ft',\n",
    "    # 'away_goals_ft',\n",
    "    # 'home_goals_ht',\n",
    "    # 'away_goals_ht',\n",
    "    'home_team_place_total',\n",
    "    'home_team_place_home',\n",
    "    'away_team_place_total',\n",
    "    'away_team_place_away',\n",
    "    'home_odds',\n",
    "    'draw_odds',\n",
    "    'away_odds',\n",
    "    'over_25_odds',\n",
    "    'under_25_odds',\n",
    "    'elo_home',\n",
    "    'elo_away',\n",
    "    'form_home',\n",
    "    'form_away',\n",
    "    # 'shots_home',\n",
    "    # 'shots_home_1h',\n",
    "    # 'shots_home_2h',\n",
    "    # 'shots_away',\n",
    "    # 'shots_away_1h',\n",
    "    # 'shots_away_2h',\n",
    "    # 'shots_on_target_home',\n",
    "    # 'shots_on_target_home_1h',\n",
    "    # 'shots_on_target_home_2h',\n",
    "    # 'shots_on_target_away',\n",
    "    # 'shots_on_target_away_1h',\n",
    "    # 'shots_on_target_away_2h',\n",
    "    # 'corners_home',\n",
    "    # 'corners_home_1h',\n",
    "    # 'corners_home_2h',\n",
    "    # 'corners_away',\n",
    "    # 'corners_away_1h',\n",
    "    # 'corners_away_2h',\n",
    "    # 'fouls_home',\n",
    "    # 'fouls_home_1h',\n",
    "    # 'fouls_home_2h',\n",
    "    # 'fouls_away',\n",
    "    # 'fouls_away_1h',\n",
    "    # 'fouls_away_2h',\n",
    "    # 'yellow_cards_home',\n",
    "    # 'yellow_cards_home_1h',\n",
    "    # 'yellow_cards_home_2h',\n",
    "    # 'yellow_cards_away',\n",
    "    # 'yellow_cards_away_1h',\n",
    "    # 'yellow_cards_away_2h',\n",
    "    # 'possession_home',\n",
    "    # 'possession_home_1h',\n",
    "    # 'possession_home_2h',\n",
    "    # 'possession_away',\n",
    "    # 'possession_away_1h',\n",
    "    # 'possession_away_2h',\n",
    "    # 'goals_scored_total_home',\n",
    "    # 'goals_conceded_total_home',\n",
    "    # 'goals_scored_total_away',\n",
    "    # 'goals_conceded_total_away',\n",
    "    # 'points_home',\n",
    "    # 'points_away',\n",
    "    # 'is_home_x',\n",
    "    'home_Overall_Rolling_GoalsScored_Mean',\n",
    "    'home_Overall_Rolling_GoalsScored_Std',\n",
    "    'home_Overall_Rolling_GoalsScored_Mean_Short',\n",
    "    'home_Overall_Momentum_GoalsScored',\n",
    "    'home_Overall_Trend_Slope_GoalsScored',\n",
    "    'home_Overall_Rolling_FirstHalfGoalsScored_Mean',\n",
    "    'home_Overall_Rolling_FirstHalfGoalsScored_Std',\n",
    "    'home_Overall_Rolling_FirstHalfGoalsScored_Mean_Short',\n",
    "    'home_Overall_Momentum_FirstHalfGoalsScored',\n",
    "    'home_Overall_Trend_Slope_FirstHalfGoalsScored',\n",
    "    'home_Overall_Rolling_Shots_Mean',\n",
    "    'home_Overall_Rolling_Shots_Std',\n",
    "    'home_Overall_Rolling_Shots_Mean_Short',\n",
    "    'home_Overall_Momentum_Shots',\n",
    "    'home_Overall_Trend_Slope_Shots',\n",
    "    'home_Overall_Rolling_Shots_1h_Mean',\n",
    "    'home_Overall_Rolling_Shots_1h_Std',\n",
    "    'home_Overall_Rolling_Shots_1h_Mean_Short',\n",
    "    'home_Overall_Momentum_Shots_1h',\n",
    "    'home_Overall_Trend_Slope_Shots_1h',\n",
    "    'home_Overall_Rolling_Corners_Mean',\n",
    "    'home_Overall_Rolling_Corners_Std',\n",
    "    'home_Overall_Rolling_Corners_Mean_Short',\n",
    "    'home_Overall_Momentum_Corners',\n",
    "    'home_Overall_Trend_Slope_Corners',\n",
    "    'home_Overall_Rolling_Corners_1h_Mean',\n",
    "    'home_Overall_Rolling_Corners_1h_Std',\n",
    "    'home_Overall_Rolling_Corners_1h_Mean_Short',\n",
    "    'home_Overall_Momentum_Corners_1h',\n",
    "    'home_Overall_Trend_Slope_Corners_1h',\n",
    "    'home_Overall_Rolling_ShotsOnTarget_Mean',\n",
    "    'home_Overall_Rolling_ShotsOnTarget_Std',\n",
    "    'home_Overall_Rolling_ShotsOnTarget_Mean_Short',\n",
    "    'home_Overall_Momentum_ShotsOnTarget',\n",
    "    'home_Overall_Trend_Slope_ShotsOnTarget',\n",
    "    'home_Overall_Rolling_ShotsOnTarget_1h_Mean',\n",
    "    'home_Overall_Rolling_ShotsOnTarget_1h_Std',\n",
    "    'home_Overall_Rolling_ShotsOnTarget_1h_Mean_Short',\n",
    "    'home_Overall_Momentum_ShotsOnTarget_1h',\n",
    "    'home_Overall_Trend_Slope_ShotsOnTarget_1h',\n",
    "    'home_Rolling_GoalsScored_Mean',\n",
    "    'home_Rolling_GoalsScored_Std',\n",
    "    'home_Rolling_GoalsScored_Mean_Short',\n",
    "    'home_Momentum_GoalsScored',\n",
    "    'home_Trend_Slope_GoalsScored',\n",
    "    'home_Rolling_FirstHalfGoalsScored_Mean',\n",
    "    'home_Rolling_FirstHalfGoalsScored_Std',\n",
    "    'home_Rolling_FirstHalfGoalsScored_Mean_Short',\n",
    "    'home_Momentum_FirstHalfGoalsScored',\n",
    "    'home_Trend_Slope_FirstHalfGoalsScored',\n",
    "    'home_Rolling_Shots_Mean',\n",
    "    'home_Rolling_Shots_Std',\n",
    "    'home_Rolling_Shots_Mean_Short',\n",
    "    'home_Momentum_Shots',\n",
    "    'home_Trend_Slope_Shots',\n",
    "    'home_Rolling_Shots_1h_Mean',\n",
    "    'home_Rolling_Shots_1h_Std',\n",
    "    'home_Rolling_Shots_1h_Mean_Short',\n",
    "    'home_Momentum_Shots_1h',\n",
    "    'home_Trend_Slope_Shots_1h',\n",
    "    'home_Rolling_Corners_Mean',\n",
    "    'home_Rolling_Corners_Std',\n",
    "    'home_Rolling_Corners_Mean_Short',\n",
    "    'home_Momentum_Corners',\n",
    "    'home_Trend_Slope_Corners',\n",
    "    'home_Rolling_Corners_1h_Mean',\n",
    "    'home_Rolling_Corners_1h_Std',\n",
    "    'home_Rolling_Corners_1h_Mean_Short',\n",
    "    'home_Momentum_Corners_1h',\n",
    "    'home_Trend_Slope_Corners_1h',\n",
    "    'home_Rolling_ShotsOnTarget_Mean',\n",
    "    'home_Rolling_ShotsOnTarget_Std',\n",
    "    'home_Rolling_ShotsOnTarget_Mean_Short',\n",
    "    'home_Momentum_ShotsOnTarget',\n",
    "    'home_Trend_Slope_ShotsOnTarget',\n",
    "    'home_Rolling_ShotsOnTarget_1h_Mean',\n",
    "    'home_Rolling_ShotsOnTarget_1h_Std',\n",
    "    'home_Rolling_ShotsOnTarget_1h_Mean_Short',\n",
    "    'home_Momentum_ShotsOnTarget_1h',\n",
    "    'home_Trend_Slope_ShotsOnTarget_1h',\n",
    "    'home_Overall_Percent_Over_1.5',\n",
    "    'home_Overall_Rolling5_Percent_Over_1.5',\n",
    "    'home_Percent_Over_1.5',\n",
    "    'home_Rolling5_Percent_Over_1.5',\n",
    "    'home_Overall_Percent_Over_2.5',\n",
    "    'home_Overall_Rolling5_Percent_Over_2.5',\n",
    "    'home_Percent_Over_2.5',\n",
    "    'home_Rolling5_Percent_Over_2.5',\n",
    "    'home_Overall_Percent_Over_3.5',\n",
    "    'home_Overall_Rolling5_Percent_Over_3.5',\n",
    "    'home_Percent_Over_3.5',\n",
    "    'home_Rolling5_Percent_Over_3.5',\n",
    "    'home_TeamPct_Over_0.5',\n",
    "    'home_TeamPct_Over_1.5',\n",
    "    'home_TeamPct_Over_2.5',\n",
    "    'home_TeamPct_Over_3.5',\n",
    "    'home_CornersPct_Over_3.5',\n",
    "    'home_CornersRolling5Pct_Over_3.5',\n",
    "    'home_CornersPct_Over_4.5',\n",
    "    'home_CornersRolling5Pct_Over_4.5',\n",
    "    'home_CornersPct_Over_5.5',\n",
    "    'home_CornersRolling5Pct_Over_5.5',\n",
    "    'home_CornersPct_Over_6.5',\n",
    "    'home_CornersRolling5Pct_Over_6.5',\n",
    "    'home_SeasonPct_Over_9.5',\n",
    "    'home_Rolling5Pct_Over_9.5',\n",
    "    'home_SeasonPct_Over_10.5',\n",
    "    'home_Rolling5Pct_Over_10.5',\n",
    "    'home_SeasonPct_Over_11.5',\n",
    "    'home_Rolling5Pct_Over_11.5',\n",
    "    # 'is_home_y',\n",
    "    'away_Overall_Rolling_GoalsScored_Mean',\n",
    "    'away_Overall_Rolling_GoalsScored_Std',\n",
    "    'away_Overall_Rolling_GoalsScored_Mean_Short',\n",
    "    'away_Overall_Momentum_GoalsScored',\n",
    "    'away_Overall_Trend_Slope_GoalsScored',\n",
    "    'away_Overall_Rolling_FirstHalfGoalsScored_Mean',\n",
    "    'away_Overall_Rolling_FirstHalfGoalsScored_Std',\n",
    "    'away_Overall_Rolling_FirstHalfGoalsScored_Mean_Short',\n",
    "    'away_Overall_Momentum_FirstHalfGoalsScored',\n",
    "    'away_Overall_Trend_Slope_FirstHalfGoalsScored',\n",
    "    'away_Overall_Rolling_Shots_Mean',\n",
    "    'away_Overall_Rolling_Shots_Std',\n",
    "    'away_Overall_Rolling_Shots_Mean_Short',\n",
    "    'away_Overall_Momentum_Shots',\n",
    "    'away_Overall_Trend_Slope_Shots',\n",
    "    'away_Overall_Rolling_Shots_1h_Mean',\n",
    "    'away_Overall_Rolling_Shots_1h_Std',\n",
    "    'away_Overall_Rolling_Shots_1h_Mean_Short',\n",
    "    'away_Overall_Momentum_Shots_1h',\n",
    "    'away_Overall_Trend_Slope_Shots_1h',\n",
    "    'away_Overall_Rolling_Corners_Mean',\n",
    "    'away_Overall_Rolling_Corners_Std',\n",
    "    'away_Overall_Rolling_Corners_Mean_Short',\n",
    "    'away_Overall_Momentum_Corners',\n",
    "    'away_Overall_Trend_Slope_Corners',\n",
    "    'away_Overall_Rolling_Corners_1h_Mean',\n",
    "    'away_Overall_Rolling_Corners_1h_Std',\n",
    "    'away_Overall_Rolling_Corners_1h_Mean_Short',\n",
    "    'away_Overall_Momentum_Corners_1h',\n",
    "    'away_Overall_Trend_Slope_Corners_1h',\n",
    "    'away_Overall_Rolling_ShotsOnTarget_Mean',\n",
    "    'away_Overall_Rolling_ShotsOnTarget_Std',\n",
    "    'away_Overall_Rolling_ShotsOnTarget_Mean_Short',\n",
    "    'away_Overall_Momentum_ShotsOnTarget',\n",
    "    'away_Overall_Trend_Slope_ShotsOnTarget',\n",
    "    'away_Overall_Rolling_ShotsOnTarget_1h_Mean',\n",
    "    'away_Overall_Rolling_ShotsOnTarget_1h_Std',\n",
    "    'away_Overall_Rolling_ShotsOnTarget_1h_Mean_Short',\n",
    "    'away_Overall_Momentum_ShotsOnTarget_1h',\n",
    "    'away_Overall_Trend_Slope_ShotsOnTarget_1h',\n",
    "    'away_Rolling_GoalsScored_Mean',\n",
    "    'away_Rolling_GoalsScored_Std',\n",
    "    'away_Rolling_GoalsScored_Mean_Short',\n",
    "    'away_Momentum_GoalsScored',\n",
    "    'away_Trend_Slope_GoalsScored',\n",
    "    'away_Rolling_FirstHalfGoalsScored_Mean',\n",
    "    'away_Rolling_FirstHalfGoalsScored_Std',\n",
    "    'away_Rolling_FirstHalfGoalsScored_Mean_Short',\n",
    "    'away_Momentum_FirstHalfGoalsScored',\n",
    "    'away_Trend_Slope_FirstHalfGoalsScored',\n",
    "    'away_Rolling_Shots_Mean',\n",
    "    'away_Rolling_Shots_Std',\n",
    "    'away_Rolling_Shots_Mean_Short',\n",
    "    'away_Momentum_Shots',\n",
    "    'away_Trend_Slope_Shots',\n",
    "    'away_Rolling_Shots_1h_Mean',\n",
    "    'away_Rolling_Shots_1h_Std',\n",
    "    'away_Rolling_Shots_1h_Mean_Short',\n",
    "    'away_Momentum_Shots_1h',\n",
    "    'away_Trend_Slope_Shots_1h',\n",
    "    'away_Rolling_Corners_Mean',\n",
    "    'away_Rolling_Corners_Std',\n",
    "    'away_Rolling_Corners_Mean_Short',\n",
    "    'away_Momentum_Corners',\n",
    "    'away_Trend_Slope_Corners',\n",
    "    'away_Rolling_Corners_1h_Mean',\n",
    "    'away_Rolling_Corners_1h_Std',\n",
    "    'away_Rolling_Corners_1h_Mean_Short',\n",
    "    'away_Momentum_Corners_1h',\n",
    "    'away_Trend_Slope_Corners_1h',\n",
    "    'away_Rolling_ShotsOnTarget_Mean',\n",
    "    'away_Rolling_ShotsOnTarget_Std',\n",
    "    'away_Rolling_ShotsOnTarget_Mean_Short',\n",
    "    'away_Momentum_ShotsOnTarget',\n",
    "    'away_Trend_Slope_ShotsOnTarget',\n",
    "    'away_Rolling_ShotsOnTarget_1h_Mean',\n",
    "    'away_Rolling_ShotsOnTarget_1h_Std',\n",
    "    'away_Rolling_ShotsOnTarget_1h_Mean_Short',\n",
    "    'away_Momentum_ShotsOnTarget_1h',\n",
    "    'away_Trend_Slope_ShotsOnTarget_1h',\n",
    "    'away_Overall_Percent_Over_1.5',\n",
    "    'away_Overall_Rolling5_Percent_Over_1.5',\n",
    "    'away_Percent_Over_1.5',\n",
    "    'away_Rolling5_Percent_Over_1.5',\n",
    "    'away_Overall_Percent_Over_2.5',\n",
    "    'away_Overall_Rolling5_Percent_Over_2.5',\n",
    "    'away_Percent_Over_2.5',\n",
    "    'away_Rolling5_Percent_Over_2.5',\n",
    "    'away_Overall_Percent_Over_3.5',\n",
    "    'away_Overall_Rolling5_Percent_Over_3.5',\n",
    "    'away_Percent_Over_3.5',\n",
    "    'away_Rolling5_Percent_Over_3.5',\n",
    "    'away_TeamPct_Over_0.5',\n",
    "    'away_TeamPct_Over_1.5',\n",
    "    'away_TeamPct_Over_2.5',\n",
    "    'away_TeamPct_Over_3.5',\n",
    "    'away_CornersPct_Over_3.5',\n",
    "    'away_CornersRolling5Pct_Over_3.5',\n",
    "    'away_CornersPct_Over_4.5',\n",
    "    'away_CornersRolling5Pct_Over_4.5',\n",
    "    'away_CornersPct_Over_5.5',\n",
    "    'away_CornersRolling5Pct_Over_5.5',\n",
    "    'away_CornersPct_Over_6.5',\n",
    "    'away_CornersRolling5Pct_Over_6.5',\n",
    "    'away_SeasonPct_Over_9.5',\n",
    "    'away_Rolling5Pct_Over_9.5',\n",
    "    'away_SeasonPct_Over_10.5',\n",
    "    'away_Rolling5Pct_Over_10.5',\n",
    "    'away_SeasonPct_Over_11.5',\n",
    "    'away_Rolling5Pct_Over_11.5'\n",
    "]"
   ],
   "id": "c91fc6401176381e",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:37:19.390149Z",
     "start_time": "2025-04-17T11:37:13.959119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pre_prepared_data(file_path):\n",
    "    data = pd.read_csv(file_path,\n",
    "                       low_memory=False)\n",
    "    # Convert 'date' column to datetime object\n",
    "    data['date'] = pd.to_datetime(data['date'], format=\"%Y-%m-%d\", errors='coerce')\n",
    "    data = data.sort_values(by='date')\n",
    "\n",
    "    # Convert today's date to a pandas Timestamp for compatibility.\n",
    "    today = pd.Timestamp(datetime.today().date())\n",
    "    data = data[data['date'] <= today]\n",
    "\n",
    "    # Clean up and finalise the match-level DataFrame\n",
    "    data.dropna(inplace=True)\n",
    "    data['ht_score'] = data['home_goals_ht'].astype(str) + '-' + data['away_goals_ht'].astype(str)\n",
    "    data['total_goals'] = data['home_goals_ft'] + data['away_goals_ft']\n",
    "    data['target'] = ((data['home_goals_ft'] > data['home_goals_ht']) | (data['away_goals_ft'] > data['away_goals_ht'])).astype(int)\n",
    "    return data\n",
    "matches = pre_prepared_data(r\"/engineered_master_data_ALL_2017+.csv\")\n",
    "\n",
    "# Process each league separately\n",
    "ht_score = matches[['ht_score']].drop_duplicates().apply(tuple, axis=1)"
   ],
   "id": "d7394273217bc600",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:37:26.351382Z",
     "start_time": "2025-04-17T11:37:26.249988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "matches_filtered = matches[matches['ht_score']=='0-0']\n",
    "data =matches_filtered.copy()\n",
    "matches_filtered"
   ],
   "id": "e6ab350b9509433e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      country  season       date  ko_time  round     home_team  \\\n",
       "0        Pol1      18 2017-08-04   1930.0      4   Wisla Plock   \n",
       "1        Den1      18 2017-08-06   1500.0      4        Odense   \n",
       "4        Rom1      18 2017-08-08   1645.0      5     Constanta   \n",
       "8        Rom1      18 2017-08-11   1900.0      6     Timisoara   \n",
       "9        Slo1      18 2017-08-11   1920.0      5       Maribor   \n",
       "...       ...     ...        ...      ...    ...           ...   \n",
       "96429    Ned2      25 2025-04-01   1900.0     26  Jong Utrecht   \n",
       "96430    Ned1      25 2025-04-02   1900.0     25     Feyenoord   \n",
       "96431    Ned2      25 2025-04-07   1900.0     26  Jong Alkmaar   \n",
       "96432    Eng4      25 2025-04-08   1945.0     25  Chesterfield   \n",
       "96433    Czh1      25 2025-04-09   1700.0     23      Slovacko   \n",
       "\n",
       "            away_team  home_goals_ft  away_goals_ft  home_goals_ht  ...  \\\n",
       "0        Wisla Krakow              0              1              0  ...   \n",
       "1             Aalborg              0              0              0  ...   \n",
       "4           Voluntari              0              0              0  ...   \n",
       "8           Constanta              0              0              0  ...   \n",
       "9             Domzale              0              0              0  ...   \n",
       "...               ...            ...            ...            ...  ...   \n",
       "96429           Venlo              0              0              0  ...   \n",
       "96430       Groningen              0              0              0  ...   \n",
       "96431  Jong Eindhoven              0              0              0  ...   \n",
       "96432      Gillingham              0              0              0  ...   \n",
       "96433  Hradec Kralove              0              0              0  ...   \n",
       "\n",
       "       away_CornersRolling5Pct_Over_6.5  away_SeasonPct_Over_9.5  \\\n",
       "0                                   0.0                 0.000000   \n",
       "1                                   0.5                 0.666667   \n",
       "4                                   0.0                 0.250000   \n",
       "8                                   0.0                 0.600000   \n",
       "9                                   0.5                 1.000000   \n",
       "...                                 ...                      ...   \n",
       "96429                               0.4                 0.645161   \n",
       "96430                               0.2                 0.384615   \n",
       "96431                               0.2                 0.718750   \n",
       "96432                               0.2                 0.225000   \n",
       "96433                               0.0                 0.592593   \n",
       "\n",
       "       away_Rolling5Pct_Over_9.5  away_SeasonPct_Over_10.5  \\\n",
       "0                       0.000000                  0.000000   \n",
       "1                       0.666667                  0.333333   \n",
       "4                       0.250000                  0.000000   \n",
       "8                       0.600000                  0.400000   \n",
       "9                       1.000000                  1.000000   \n",
       "...                          ...                       ...   \n",
       "96429                   0.600000                  0.516129   \n",
       "96430                   0.600000                  0.230769   \n",
       "96431                   0.400000                  0.468750   \n",
       "96432                   0.000000                  0.125000   \n",
       "96433                   0.400000                  0.481481   \n",
       "\n",
       "       away_Rolling5Pct_Over_10.5  away_SeasonPct_Over_11.5  \\\n",
       "0                        0.000000                  0.000000   \n",
       "1                        0.333333                  0.333333   \n",
       "4                        0.000000                  0.000000   \n",
       "8                        0.400000                  0.400000   \n",
       "9                        1.000000                  1.000000   \n",
       "...                           ...                       ...   \n",
       "96429                    0.400000                  0.354839   \n",
       "96430                    0.200000                  0.192308   \n",
       "96431                    0.400000                  0.375000   \n",
       "96432                    0.000000                  0.100000   \n",
       "96433                    0.400000                  0.407407   \n",
       "\n",
       "       away_Rolling5Pct_Over_11.5  ht_score  total_goals  target  \n",
       "0                        0.000000       0-0            1       1  \n",
       "1                        0.333333       0-0            0       0  \n",
       "4                        0.000000       0-0            0       0  \n",
       "8                        0.400000       0-0            0       0  \n",
       "9                        1.000000       0-0            0       0  \n",
       "...                           ...       ...          ...     ...  \n",
       "96429                    0.200000       0-0            0       0  \n",
       "96430                    0.200000       0-0            0       0  \n",
       "96431                    0.400000       0-0            0       0  \n",
       "96432                    0.000000       0-0            0       0  \n",
       "96433                    0.400000       0-0            0       0  \n",
       "\n",
       "[35410 rows x 287 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>season</th>\n",
       "      <th>date</th>\n",
       "      <th>ko_time</th>\n",
       "      <th>round</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_goals_ft</th>\n",
       "      <th>away_goals_ft</th>\n",
       "      <th>home_goals_ht</th>\n",
       "      <th>...</th>\n",
       "      <th>away_CornersRolling5Pct_Over_6.5</th>\n",
       "      <th>away_SeasonPct_Over_9.5</th>\n",
       "      <th>away_Rolling5Pct_Over_9.5</th>\n",
       "      <th>away_SeasonPct_Over_10.5</th>\n",
       "      <th>away_Rolling5Pct_Over_10.5</th>\n",
       "      <th>away_SeasonPct_Over_11.5</th>\n",
       "      <th>away_Rolling5Pct_Over_11.5</th>\n",
       "      <th>ht_score</th>\n",
       "      <th>total_goals</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pol1</td>\n",
       "      <td>18</td>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Wisla Plock</td>\n",
       "      <td>Wisla Krakow</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0-0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Den1</td>\n",
       "      <td>18</td>\n",
       "      <td>2017-08-06</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Odense</td>\n",
       "      <td>Aalborg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rom1</td>\n",
       "      <td>18</td>\n",
       "      <td>2017-08-08</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Constanta</td>\n",
       "      <td>Voluntari</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rom1</td>\n",
       "      <td>18</td>\n",
       "      <td>2017-08-11</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>6</td>\n",
       "      <td>Timisoara</td>\n",
       "      <td>Constanta</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Slo1</td>\n",
       "      <td>18</td>\n",
       "      <td>2017-08-11</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Maribor</td>\n",
       "      <td>Domzale</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96429</th>\n",
       "      <td>Ned2</td>\n",
       "      <td>25</td>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>26</td>\n",
       "      <td>Jong Utrecht</td>\n",
       "      <td>Venlo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96430</th>\n",
       "      <td>Ned1</td>\n",
       "      <td>25</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Feyenoord</td>\n",
       "      <td>Groningen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96431</th>\n",
       "      <td>Ned2</td>\n",
       "      <td>25</td>\n",
       "      <td>2025-04-07</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>26</td>\n",
       "      <td>Jong Alkmaar</td>\n",
       "      <td>Jong Eindhoven</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96432</th>\n",
       "      <td>Eng4</td>\n",
       "      <td>25</td>\n",
       "      <td>2025-04-08</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Chesterfield</td>\n",
       "      <td>Gillingham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96433</th>\n",
       "      <td>Czh1</td>\n",
       "      <td>25</td>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>23</td>\n",
       "      <td>Slovacko</td>\n",
       "      <td>Hradec Kralove</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35410 rows × 287 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:37:31.470568Z",
     "start_time": "2025-04-17T11:37:31.463964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, matthews_corrcoef, accuracy_score)\n",
    "\n",
    "# def replicate_run_from_csv_row(data, features, row):\n",
    "#     \"\"\"\n",
    "#     Replicates a model run from a single row in a metrics CSV for one of three supported models:\n",
    "#       - MLPClassifier (sklearn)\n",
    "#       - XGBClassifier (xgboost)\n",
    "#       - RandomForestClassifier (sklearn)\n",
    "#\n",
    "#     The CSV row is assumed to have columns 'SMOTE', 'Probability_Threshold', 'Params', and 'Model'.\n",
    "#     The function applies SMOTE only to the training data, builds a pipeline with a scaler and the classifier,\n",
    "#     fits the model, applies a custom probability threshold for classification, and then computes evaluation metrics.\n",
    "#     \"\"\"\n",
    "#     # Extract parameters from the CSV row.\n",
    "#     smote_level = row['SMOTE']\n",
    "#     threshold = row['Probability_Threshold']\n",
    "#     param_dict = ast.literal_eval(row['Params']) if isinstance(row['Params'], str) else row['Params']\n",
    "#     model_name = row['Model']\n",
    "#\n",
    "#     # Prepare data: separate features and target, then perform time-series split.\n",
    "#     X = data[features]\n",
    "#     y = data['target']\n",
    "#     train_size = int(len(data) * 0.8)\n",
    "#     X_train = X.iloc[:train_size]\n",
    "#     X_test = X.iloc[train_size:]\n",
    "#     y_train = y.iloc[:train_size]\n",
    "#     y_test = y.iloc[train_size:]\n",
    "#\n",
    "#     # Apply SMOTE to the training set.\n",
    "#     smote = SMOTE(sampling_strategy=float(smote_level), random_state=42)\n",
    "#     X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "#\n",
    "#     # Build a classifier based on the model name.\n",
    "#     if model_name == \"MLP\":\n",
    "#         from sklearn.neural_network import MLPClassifier\n",
    "#         classifier = MLPClassifier(random_state=42, max_iter=500)\n",
    "#     elif model_name == \"XGBoost\":\n",
    "#         from xgboost import XGBClassifier\n",
    "#         classifier = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "#     elif model_name in [\"Random Forest\", \"RandomForest\", \"Radnom forrest\"]:\n",
    "#         from sklearn.ensemble import RandomForestClassifier\n",
    "#         classifier = RandomForestClassifier(random_state=42)\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "#\n",
    "#     # Build the pipeline with a scaler and the appropriate classifier.\n",
    "#     pipeline = ImbPipeline([\n",
    "#         ('scaler', StandardScaler()),\n",
    "#         ('classifier', classifier)\n",
    "#     ])\n",
    "#\n",
    "#     # Set the classifier parameters from the CSV row.\n",
    "#     pipeline.set_params(**param_dict)\n",
    "#\n",
    "#     # Fit the pipeline on the resampled training data.\n",
    "#     pipeline.fit(X_train_res, y_train_res)\n",
    "#\n",
    "#     # Predict probabilities on the test set and apply the custom threshold.\n",
    "#     y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "#     y_pred = (y_proba >= float(threshold)).astype(int)\n",
    "#\n",
    "#     # Compute evaluation metrics.\n",
    "#     metrics = {\n",
    "#         'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "#         'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "#         'F1': f1_score(y_test, y_pred, zero_division=0),\n",
    "#         'AUC': roc_auc_score(y_test, y_proba),\n",
    "#         'MCC': matthews_corrcoef(y_test, y_pred),\n",
    "#         'Accuracy': accuracy_score(y_test, y_pred),\n",
    "#         'Test_Sample_Size': np.sum(y_pred),\n",
    "#         'Confusion_Matrix': confusion_matrix(y_test, y_pred)\n",
    "#     }\n",
    "#\n",
    "#     return metrics\n",
    "\n",
    "def replicate_run_from_csv_row(data, features, row):\n",
    "    \"\"\"\n",
    "    Replicates a model run from a single row in a metrics CSV for one of three supported models:\n",
    "      - MLPClassifier (sklearn)\n",
    "      - XGBClassifier (xgboost)\n",
    "      - RandomForestClassifier (sklearn)\n",
    "\n",
    "    The CSV row is assumed to have columns 'SMOTE', 'Probability_Threshold', 'Params', and 'Model'.\n",
    "    The function applies SMOTE only to the training data (if SMOTE is specified), builds a pipeline\n",
    "    with a scaler and the classifier, fits the model, applies a custom probability threshold for\n",
    "    classification, and then computes evaluation metrics.\n",
    "    \"\"\"\n",
    "    # 1) Extract parameters\n",
    "    smote_level = row['SMOTE']\n",
    "    threshold = float(row['Probability_Threshold'])\n",
    "    param_dict = ast.literal_eval(row['Params']) if isinstance(row['Params'], str) else row['Params']\n",
    "    model_name = row['Model']\n",
    "\n",
    "    # 2) Split data\n",
    "    X = data[features]\n",
    "    y = data['target']\n",
    "    split = int(len(data) * 0.8)\n",
    "    X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "    y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
    "\n",
    "    # 3) Conditionally apply SMOTE\n",
    "    if pd.notna(smote_level):\n",
    "        smote = SMOTE(sampling_strategy=float(smote_level), random_state=42)\n",
    "        X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "    else:\n",
    "        X_train_res, y_train_res = X_train, y_train\n",
    "\n",
    "    # 4) Choose model\n",
    "    if model_name == \"MLP\":\n",
    "        from sklearn.neural_network import MLPClassifier\n",
    "        classifier = MLPClassifier(random_state=42, max_iter=500)\n",
    "    elif model_name == \"XGBoost\":\n",
    "        from xgboost import XGBClassifier\n",
    "        classifier = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "    elif model_name in [\"Random Forest\", \"RandomForest\", \"Radnom forrest\"]:\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        classifier = RandomForestClassifier(random_state=42)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "\n",
    "    # 5) Build pipeline\n",
    "    pipeline = ImbPipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "    pipeline.set_params(**param_dict)\n",
    "\n",
    "    # 6) Fit\n",
    "    pipeline.fit(X_train_res, y_train_res)\n",
    "\n",
    "    # 7) Predict with custom threshold\n",
    "    y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "    y_pred  = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    # 8) Metrics\n",
    "    return {\n",
    "        'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "        'Recall':    recall_score(y_test, y_pred, zero_division=0),\n",
    "        'F1':        f1_score(y_test, y_pred, zero_division=0),\n",
    "        'AUC':       roc_auc_score(y_test, y_proba),\n",
    "        'MCC':       matthews_corrcoef(y_test, y_pred),\n",
    "        'Accuracy':  accuracy_score(y_test, y_pred),\n",
    "        'Test_Sample_Size': int(y_test.sum()),\n",
    "        'Confusion_Matrix': confusion_matrix(y_test, y_pred)\n",
    "    }"
   ],
   "id": "63e697756e8b41a2",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:37:38.746265Z",
     "start_time": "2025-04-17T11:37:36.225500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "row = results_df.iloc[0]\n",
    "metrics = replicate_run_from_csv_row(data, features, row)\n",
    "print(metrics)"
   ],
   "id": "2a811571cbe416ad",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leere\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:37:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision': np.float64(0.8640776699029126), 'Recall': np.float64(0.03377609108159393), 'F1': np.float64(0.06501095690284879), 'AUC': np.float64(0.5863180211200053), 'MCC': np.float64(0.04757650504599813), 'Accuracy': 0.277040384072296, 'Test_Sample_Size': 5270, 'Confusion_Matrix': array([[1784,   28],\n",
      "       [5092,  178]])}\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:43:21.696403Z",
     "start_time": "2025-04-17T11:43:05.760819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import ast\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_and_save_model(data, features, row, output_dir):\n",
    "    \"\"\"\n",
    "    Trains a model for a specific league using the parameters provided in a row from results_df,\n",
    "    and saves the trained pipeline for future predictions only if the 'Precision_Test' value is > 0.8.\n",
    "\n",
    "    Expected CSV row columns:\n",
    "      - 'League'                : Identifier for the league (used for naming the saved file)\n",
    "      - 'SMOTE'                 : The sampling strategy for SMOTE (or NaN for no SMOTE)\n",
    "      - 'Probability_Threshold' : The custom threshold for predictions\n",
    "      - 'Precision_Test'        : The precision metric (the model is only saved if this > 0.8)\n",
    "      - 'Params'                : A string/dict of classifier parameters (e.g. hyperparameters)\n",
    "      - 'Model'                 : The model type (\"MLP\", \"XGBoost\", or \"Random Forest\")\n",
    "\n",
    "    The function performs a time-series split (first 80% for training), applies SMOTE only to the training set\n",
    "    if the desired SMOTE ratio is greater than the current ratio, and fits the model.\n",
    "\n",
    "    The saved dictionary includes:\n",
    "      - 'pipeline': the trained model pipeline,\n",
    "      - 'threshold': the probability threshold (float),\n",
    "      - 'league': the league identifier,\n",
    "      - 'smote_level': the SMOTE level used (or None).\n",
    "\n",
    "    The model is only saved if Precision_Test > 0.8.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import ast\n",
    "    from collections import Counter\n",
    "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    import joblib\n",
    "\n",
    "    # Ensure the output directory exists.\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Extract parameters from the row.\n",
    "    smote_level = row['SMOTE']\n",
    "    threshold = row['Probability_Threshold']\n",
    "    precision_test = row['Precision_Test']\n",
    "    param_dict = ast.literal_eval(row['Params']) if isinstance(row['Params'], str) else row['Params']\n",
    "    model_name = row['Model']\n",
    "    ht_score = row.get('HT_Score', 'unknown')\n",
    "\n",
    "    # Prepare data: separate features and target, then perform a time-series split.\n",
    "    X = data[features]\n",
    "    y = data['target']\n",
    "    train_size = int(len(data) * 0.8)\n",
    "    X_train = X.iloc[:train_size]\n",
    "    y_train = y.iloc[:train_size]\n",
    "\n",
    "    # Apply SMOTE if specified.\n",
    "    if pd.isna(smote_level):\n",
    "        X_train_res, y_train_res = X_train, y_train\n",
    "        used_smote_level = None\n",
    "    else:\n",
    "        # Determine the current minority-to-majority ratio.\n",
    "        counts = Counter(y_train)\n",
    "        minority_class = min(counts, key=counts.get)\n",
    "        majority_class = max(counts, key=counts.get)\n",
    "        current_ratio = counts[minority_class] / counts[majority_class]\n",
    "        desired_ratio = float(smote_level)\n",
    "\n",
    "        # Apply SMOTE only if desired_ratio is greater than the current ratio.\n",
    "        if desired_ratio <= current_ratio:\n",
    "            print(f\"Warning: Specified SMOTE level ({desired_ratio:.2f}) is less than or equal to current ratio ({current_ratio:.2f}) for league {league}. Skipping SMOTE.\")\n",
    "            X_train_res, y_train_res = X_train, y_train\n",
    "            used_smote_level = None\n",
    "        else:\n",
    "            smote = SMOTE(sampling_strategy=desired_ratio, random_state=42)\n",
    "            X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "            used_smote_level = desired_ratio\n",
    "\n",
    "    # Instantiate the classifier based on the model name.\n",
    "    if model_name == \"MLP\":\n",
    "        classifier = MLPClassifier(random_state=42, max_iter=500)\n",
    "    elif model_name == \"XGBoost\":\n",
    "        classifier = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "    elif model_name in [\"Random Forest\", \"RandomForest\", \"Radnom forrest\"]:\n",
    "        classifier = RandomForestClassifier(random_state=42)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "\n",
    "    # Build the pipeline with a scaler and the classifier.\n",
    "    pipeline = ImbPipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "    pipeline.set_params(**param_dict)\n",
    "\n",
    "    # Fit the pipeline on the (potentially resampled) training data.\n",
    "    pipeline.fit(X_train_res, y_train_res)\n",
    "\n",
    "    # Check if the precision test meets the requirement.\n",
    "    if precision_test > 0.8:\n",
    "        # Save the trained pipeline along with the threshold, league, and SMOTE level.\n",
    "        model_dict = {\n",
    "            'pipeline': pipeline,\n",
    "            'threshold': float(threshold),\n",
    "            'ht_score': ht_score,\n",
    "            'smote_level': used_smote_level\n",
    "        }\n",
    "        file_name = f\"trained_model_{ht_score}.pkl\"\n",
    "        file_path = os.path.join(output_dir, file_name)\n",
    "        joblib.dump(model_dict, file_path)\n",
    "        print(f\"Saved trained model for league '{ht_score}' to {file_path}\")\n",
    "        return file_path\n",
    "    else:\n",
    "        print(f\"Model for league '{ht_score}' not saved because Precision_Test ({precision_test}) is not greater than 0.8.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_and_save_all_models(data, features, results_df, output_dir):\n",
    "    \"\"\"\n",
    "    Iterates over each row in results_df (each representing parameters for a league model),\n",
    "    trains the model using those parameters, and saves the model pipeline for future predictions.\n",
    "\n",
    "    Returns a list of file paths of the saved models.\n",
    "    \"\"\"\n",
    "    saved_files = []\n",
    "    for idx, row in results_df.iterrows():\n",
    "        ht_score = row['HT_Score'].strip(\"(',);\")\n",
    "        data = matches[matches['ht_score']==ht_score]\n",
    "        try:\n",
    "            file_path = train_and_save_model(data, features, row, output_dir)\n",
    "            saved_files.append(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error training model for row index {idx} (HT Score: {row.get('HT_Score','unknown')}): {e}\")\n",
    "    return saved_files\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `data` is your DataFrame containing a 'target' column and the feature columns,\n",
    "# `features` is your list of feature column names, and `results_df` is the DataFrame\n",
    "# with each row containing model parameters for a league model (with 'League', 'SMOTE',\n",
    "# 'Probability_Threshold', 'Params', and 'Model' columns).\n",
    "#\n",
    "output_directory = r\"path_ht_score\\to\\save\\models\"\n",
    "saved_model_files = train_and_save_all_models(data, features, results_df, output_directory)\n",
    "#print(\"Saved model files:\", saved_model_files)\n"
   ],
   "id": "4c48feccaa62e638",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leere\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:43:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model for league '('0-0',)' to path_ht_score\\to\\save\\models\\trained_model_('0-0',).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leere\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:43:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model for league '('0-1',)' to path_ht_score\\to\\save\\models\\trained_model_('0-1',).pkl\n",
      "Saved trained model for league '('0-2',)' to path_ht_score\\to\\save\\models\\trained_model_('0-2',).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leere\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:43:16] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model for league '('1-0',)' to path_ht_score\\to\\save\\models\\trained_model_('1-0',).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leere\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:43:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model for league '('1-1',)' to path_ht_score\\to\\save\\models\\trained_model_('1-1',).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leere\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:43:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model for league '('1-2',)' to path_ht_score\\to\\save\\models\\trained_model_('1-2',).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leere\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:43:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model for league '('2-0',)' to path_ht_score\\to\\save\\models\\trained_model_('2-0',).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leere\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:43:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model for league '('2-1',)' to path_ht_score\\to\\save\\models\\trained_model_('2-1',).pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leere\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:43:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model for league '('3-0',)' to path_ht_score\\to\\save\\models\\trained_model_('3-0',).pkl\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:44:49.180277Z",
     "start_time": "2025-04-17T11:44:49.076513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score, roc_auc_score,\n",
    "                             matthews_corrcoef, accuracy_score, confusion_matrix)\n",
    "\n",
    "def test_saved_model(saved_model_path, data, features):\n",
    "    \"\"\"\n",
    "    Loads a saved model (including its pipeline, probability threshold, SMOTE level, and league)\n",
    "    and evaluates it on the test set.\n",
    "\n",
    "    Assumes the data is to be split using a time-series approach (first 80% used for training, last 20% for testing)\n",
    "    and that the saved model dictionary contains keys:\n",
    "      - 'pipeline': the trained model pipeline,\n",
    "      - 'threshold': the probability threshold (float) used for converting probabilities to predictions,\n",
    "      - 'league': the league identifier,\n",
    "      - 'smote_level': the SMOTE level used during training (or None if SMOTE was not applied).\n",
    "\n",
    "    Returns a dictionary of evaluation metrics computed on the test set, including the SMOTE level.\n",
    "    \"\"\"\n",
    "    # Load the saved model dictionary\n",
    "    model_dict = joblib.load(saved_model_path)\n",
    "    pipeline = model_dict['pipeline']\n",
    "    threshold = model_dict['threshold']\n",
    "    ht_score = model_dict['ht_score']\n",
    "    smote_level = model_dict.get('smote_level')\n",
    "\n",
    "    print(f\"Testing model for league '{ht_score}' using threshold: {threshold}\")\n",
    "    if smote_level is not None:\n",
    "        print(f\"Using SMOTE level: {smote_level}\")\n",
    "    else:\n",
    "        print(\"No SMOTE was applied during training.\")\n",
    "\n",
    "    # Prepare the test set (using 80/20 time-series split as in training)\n",
    "    X = data[features]\n",
    "    y = data['target']\n",
    "    train_size = int(len(data) * 0.8)\n",
    "    X_test = X.iloc[train_size:]\n",
    "    y_test = y.iloc[train_size:]\n",
    "\n",
    "    # Generate predicted probabilities and apply the custom threshold to get predictions\n",
    "    y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_proba >= float(threshold)).astype(int)\n",
    "\n",
    "    # Compute evaluation metrics on the test set\n",
    "    metrics = {\n",
    "        'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "        'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "        'F1': f1_score(y_test, y_pred, zero_division=0),\n",
    "        'AUC': roc_auc_score(y_test, y_proba),\n",
    "        'MCC': matthews_corrcoef(y_test, y_pred),\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Test_Sample_Size': int(np.sum(y_pred)),\n",
    "        'Confusion_Matrix': confusion_matrix(y_test, y_pred),\n",
    "        'SMOTE_Level': smote_level\n",
    "    }\n",
    "\n",
    "    print(\"Test metrics:\")\n",
    "    for key, value in metrics.items():\n",
    "         print(f\"{key}: {value}\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Example usage:\n",
    "# Assuming the saved model for league Bel1 is in the file specified below, and you have your\n",
    "# `data` DataFrame and list of `features` already defined:\n",
    "test_model_path = r\"/Goals/2H_goal/ht_scoreline/path_ht_score\\to\\save\\models\\trained_model_('2-0',).pkl\"\n",
    "ht_score = test_model_path.split(\"trained_model_\")[1].split(\".pkl\")[0].strip(\"(',)\")\n",
    "print(ht_score)\n",
    "data = matches[matches['ht_score']==ht_score]\n",
    "test_metrics = test_saved_model(test_model_path, data, features)\n"
   ],
   "id": "97ae462ba431b60c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-0\n",
      "Testing model for league '('2-0',)' using threshold: 0.76\n",
      "Using SMOTE level: 0.41\n",
      "Test metrics:\n",
      "Precision: 0.926829268292683\n",
      "Recall: 0.1956745623069001\n",
      "F1: 0.3231292517006803\n",
      "AUC: 0.5654623346453546\n",
      "MCC: 0.13051495189118867\n",
      "Accuracy: 0.3310924369747899\n",
      "Test_Sample_Size: 205\n",
      "Confusion_Matrix: [[204  15]\n",
      " [781 190]]\n",
      "SMOTE_Level: 0.41\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:44:40.806486Z",
     "start_time": "2025-04-17T11:44:40.792971Z"
    }
   },
   "cell_type": "code",
   "source": "results_df",
   "id": "ed9b33b825c99947",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   HT_Score    Model  SMOTE  Precision_Test  Precision_Test/Train_Ratio  \\\n",
       "0  ('0-0',)  XGBoost    NaN          0.8641                      0.9350   \n",
       "1  ('0-1',)  XGBoost   0.62          0.8711                      0.9283   \n",
       "2  ('0-2',)      MLP    NaN          0.8475                      0.9745   \n",
       "3  ('1-0',)  XGBoost   0.63          0.8791                      0.9422   \n",
       "4  ('1-1',)  XGBoost    NaN          0.9028                      0.9166   \n",
       "5  ('1-2',)  XGBoost   0.90          0.8564                      0.9653   \n",
       "6  ('2-0',)  XGBoost   0.41          0.9268                      0.9914   \n",
       "7  ('2-1',)  XGBoost   0.47          0.9028                      0.9053   \n",
       "8  ('3-0',)  XGBoost   0.73          0.8700                      0.9321   \n",
       "\n",
       "   Probability_Threshold                                             Params  \n",
       "0                   0.80  {'classifier__colsample_bytree': 0.7, 'classif...  \n",
       "1                   0.81  {'classifier__colsample_bytree': 0.8, 'classif...  \n",
       "2                   0.81  {'classifier__activation': 'relu', 'classifier...  \n",
       "3                   0.81  {'classifier__colsample_bytree': 0.8, 'classif...  \n",
       "4                   0.81  {'classifier__colsample_bytree': 0.7, 'classif...  \n",
       "5                   0.60  {'classifier__colsample_bytree': 0.7, 'classif...  \n",
       "6                   0.76  {'classifier__colsample_bytree': 0.8, 'classif...  \n",
       "7                   0.80  {'classifier__colsample_bytree': 0.7, 'classif...  \n",
       "8                   0.65  {'classifier__colsample_bytree': 0.8, 'classif...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HT_Score</th>\n",
       "      <th>Model</th>\n",
       "      <th>SMOTE</th>\n",
       "      <th>Precision_Test</th>\n",
       "      <th>Precision_Test/Train_Ratio</th>\n",
       "      <th>Probability_Threshold</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('0-0',)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8641</td>\n",
       "      <td>0.9350</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.7, 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('0-1',)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.8711</td>\n",
       "      <td>0.9283</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('0-2',)</td>\n",
       "      <td>MLP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8475</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__activation': 'relu', 'classifier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('1-0',)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.8791</td>\n",
       "      <td>0.9422</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('1-1',)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9166</td>\n",
       "      <td>0.81</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.7, 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>('1-2',)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.8564</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>0.60</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.7, 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>('2-0',)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.9268</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.76</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>('2-1',)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.7, 'classif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>('3-0',)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.8700</td>\n",
       "      <td>0.9321</td>\n",
       "      <td>0.65</td>\n",
       "      <td>{'classifier__colsample_bytree': 0.8, 'classif...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
