{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-30T07:10:49.817324Z",
     "start_time": "2025-05-30T07:10:49.810992Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:10:49.849594Z",
     "start_time": "2025-05-30T07:10:49.842567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set end_period as a date object.\n",
    "end_period = pd.to_datetime(\"2025-06-01\").date()"
   ],
   "id": "feb08a08ace843d8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:10:50.906719Z",
     "start_time": "2025-05-30T07:10:49.874494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Path to the .xls file\n",
    "file_path = r\"C:\\Users\\leere\\OneDrive\\Desktop\\RAW DATA\\ml_goals.xls\"\n",
    "\n",
    "# Load the Excel file into a DataFrame\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()\n"
   ],
   "id": "6a750db563228e74",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING *** file size (18703411) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  country  sezonul   datameci  orameci  etapa  txtechipa1  \\\n",
       "0    Ita1       25 2024-02-06     1945     14  Fiorentina   \n",
       "1    Mex1       25 2024-07-05     2345      1      Puebla   \n",
       "2    Mex1       25 2024-07-06      200      1   Queretaro   \n",
       "3    Mex1       25 2024-07-06      410      1      Juarez   \n",
       "4    Mex1       25 2024-07-07        0      1    San Luis   \n",
       "\n",
       "            txtechipa2  scor1  scor2  scorp1  ...  yellowa2  ballph  ballph1  \\\n",
       "0                Inter      3      0       0  ...         0      28       35   \n",
       "1        Santos Laguna      1      0       0  ...         2      40       39   \n",
       "2  Tijuana de Caliente      1      2       0  ...         0      37       33   \n",
       "3                Atlas      2      2       1  ...         0      55       66   \n",
       "4         Club America      2      1       1  ...         1      37       41   \n",
       "\n",
       "   ballph2  ballpa  ballpa1  ballpa2  stare  codechipa1  codechipa2  \n",
       "0       21      72       65       79      J        2008        2002  \n",
       "1       41      60       61       59      J       41017       41008  \n",
       "2       41      63       67       59      J       41011       41006  \n",
       "3       44      45       34       56      J       41020       41002  \n",
       "4       33      63       59       67      J       41019       41012  \n",
       "\n",
       "[5 rows x 73 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>sezonul</th>\n",
       "      <th>datameci</th>\n",
       "      <th>orameci</th>\n",
       "      <th>etapa</th>\n",
       "      <th>txtechipa1</th>\n",
       "      <th>txtechipa2</th>\n",
       "      <th>scor1</th>\n",
       "      <th>scor2</th>\n",
       "      <th>scorp1</th>\n",
       "      <th>...</th>\n",
       "      <th>yellowa2</th>\n",
       "      <th>ballph</th>\n",
       "      <th>ballph1</th>\n",
       "      <th>ballph2</th>\n",
       "      <th>ballpa</th>\n",
       "      <th>ballpa1</th>\n",
       "      <th>ballpa2</th>\n",
       "      <th>stare</th>\n",
       "      <th>codechipa1</th>\n",
       "      <th>codechipa2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ita1</td>\n",
       "      <td>25</td>\n",
       "      <td>2024-02-06</td>\n",
       "      <td>1945</td>\n",
       "      <td>14</td>\n",
       "      <td>Fiorentina</td>\n",
       "      <td>Inter</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>21</td>\n",
       "      <td>72</td>\n",
       "      <td>65</td>\n",
       "      <td>79</td>\n",
       "      <td>J</td>\n",
       "      <td>2008</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mex1</td>\n",
       "      <td>25</td>\n",
       "      <td>2024-07-05</td>\n",
       "      <td>2345</td>\n",
       "      <td>1</td>\n",
       "      <td>Puebla</td>\n",
       "      <td>Santos Laguna</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "      <td>60</td>\n",
       "      <td>61</td>\n",
       "      <td>59</td>\n",
       "      <td>J</td>\n",
       "      <td>41017</td>\n",
       "      <td>41008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mex1</td>\n",
       "      <td>25</td>\n",
       "      <td>2024-07-06</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>Queretaro</td>\n",
       "      <td>Tijuana de Caliente</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>63</td>\n",
       "      <td>67</td>\n",
       "      <td>59</td>\n",
       "      <td>J</td>\n",
       "      <td>41011</td>\n",
       "      <td>41006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mex1</td>\n",
       "      <td>25</td>\n",
       "      <td>2024-07-06</td>\n",
       "      <td>410</td>\n",
       "      <td>1</td>\n",
       "      <td>Juarez</td>\n",
       "      <td>Atlas</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>66</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>34</td>\n",
       "      <td>56</td>\n",
       "      <td>J</td>\n",
       "      <td>41020</td>\n",
       "      <td>41002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mex1</td>\n",
       "      <td>25</td>\n",
       "      <td>2024-07-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>San Luis</td>\n",
       "      <td>Club America</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>67</td>\n",
       "      <td>J</td>\n",
       "      <td>41019</td>\n",
       "      <td>41012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:10:50.968865Z",
     "start_time": "2025-05-30T07:10:50.951707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "column_dict = {\n",
    "    \"country\": \"country\",\n",
    "    \"league\": \"league\",\n",
    "    \"sezonul\": \"season\",\n",
    "    \"datameci\": \"date\",\n",
    "    \"orameci\": \"ko_time\",\n",
    "    \"etapa\": \"round\",\n",
    "    \"txtechipa1\": \"home_team\",\n",
    "    \"txtechipa2\": \"away_team\",\n",
    "    \"scor1\": \"home_goals_ft\",\n",
    "    \"scor2\": \"away_goals_ft\",\n",
    "    \"scorp1\": \"home_goals_ht\",\n",
    "    \"scorp2\": \"away_goals_ht\",\n",
    "    \"place1\": \"home_team_place_total\",\n",
    "    \"place1a\": \"home_team_place_home\",\n",
    "    \"place2\": \"away_team_place_total\",\n",
    "    \"place2d\": \"away_team_place_away\",\n",
    "    \"cotaa\": \"home_odds\",\n",
    "    \"cotae\": \"draw_odds\",\n",
    "    \"cotad\": \"away_odds\",\n",
    "    # \"cotao0\": \"\",\n",
    "    # \"cotao1\": \"\",\n",
    "    \"cotao\": \"over_25_odds\",\n",
    "    # \"cotao3\": \"\",\n",
    "    # \"cotao4\": \"\",\n",
    "    # \"cotau0\": \"\",\n",
    "    # \"cotau1\": \"\",\n",
    "    \"cotau\": \"under_25_odds\",\n",
    "    # \"cotau3\": \"\",\n",
    "    # \"cotau4\": \"\",\n",
    "    # \"gg\": \"\",\n",
    "    # \"ng\": \"\",\n",
    "    \"elohomeo\": \"elo_home\",\n",
    "    \"eloawayo\": \"elo_away\",\n",
    "    \"formah\": \"form_home\",\n",
    "    \"formaa\": \"form_away\",\n",
    "    \"suth\": \"shots_home\",\n",
    "    \"suth1\": \"shots_home_1h\",\n",
    "    \"suth2\": \"shots_home_2h\",\n",
    "    \"suta\": \"shots_away\",\n",
    "    \"suta1\": \"shots_away_1h\",\n",
    "    \"suta2\": \"shots_away_2h\",\n",
    "    \"sutht\": \"shots_on_target_home\",\n",
    "    \"sutht1\": \"shots_on_target_home_1h\",\n",
    "    \"sutht2\": \"shots_on_target_home_2h\",\n",
    "    \"sutat\": \"shots_on_target_away\",\n",
    "    \"sutat1\": \"shots_on_target_away_1h\",\n",
    "    \"sutat2\": \"shots_on_target_away_2h\",\n",
    "    \"corh\": \"corners_home\",\n",
    "    \"corh1\": \"corners_home_1h\",\n",
    "    \"corh2\": \"corners_home_2h\",\n",
    "    \"cora\": \"corners_away\",\n",
    "    \"cora1\": \"corners_away_1h\",\n",
    "    \"cora2\": \"corners_away_2h\",\n",
    "    \"foulsh\": \"fouls_home\",\n",
    "    \"foulsh1\": \"fouls_home_1h\",\n",
    "    \"foulsh2\": \"fouls_home_2h\",\n",
    "    \"foulsa\": \"fouls_away\",\n",
    "    \"foulsa1\": \"fouls_away_1h\",\n",
    "    \"foulsa2\": \"fouls_away_2h\",\n",
    "    \"yellowh\": \"yellow_cards_home\",\n",
    "    \"yellowh1\": \"yellow_cards_home_1h\",\n",
    "    \"yellowh2\": \"yellow_cards_home_2h\",\n",
    "    \"yellowa\": \"yellow_cards_away\",\n",
    "    \"yellowa1\": \"yellow_cards_away_1h\",\n",
    "    \"yellowa2\": \"yellow_cards_away_2h\",\n",
    "    \"ballph\": \"possession_home\",\n",
    "    \"ballph1\": \"possession_home_1h\",\n",
    "    \"ballph2\": \"possession_home_2h\",\n",
    "    \"ballpa\": \"possession_away\",\n",
    "    \"ballpa1\": \"possession_away_1h\",\n",
    "    \"ballpa2\": \"possession_away_2h\",\n",
    "    \"gsh\": \"goals_scored_total_home\",\n",
    "    \"gch\": \"goals_conceded_total_home\",\n",
    "    \"gsa\": \"goals_scored_total_away\",\n",
    "    \"gca\": \"goals_conceded_total_away\",\n",
    "    # \"stare\": \"\",\n",
    "    # \"codechipa1\": \"\",\n",
    "    # \"codechipa2\": \"\"\n",
    "}\n",
    "\n",
    "df = df.rename(columns=column_dict).filter(items=column_dict.values())\n",
    "data = df.copy()\n",
    "#data"
   ],
   "id": "6ad425c0af9a693f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:10:51.021906Z",
     "start_time": "2025-05-30T07:10:50.993595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert 'date' column to datetime object\n",
    "data['date'] = pd.to_datetime(data['date'], format=\"%d/%m/%Y\", errors='coerce')\n",
    "\n",
    "# Order by date\n",
    "data = data.sort_values(by='date')\n",
    "\n",
    "# Filter out future dates (ensure data does not go beyond today)\n",
    "today = datetime.today().date()\n",
    "data = data[data['date'].dt.date <= end_period]\n",
    "\n",
    "# Create a mask for matches that have been played (i.e. date is less than today)\n",
    "played_mask = data['date'].dt.date < today\n",
    "\n",
    "# Calculate home points for played matches only.\n",
    "data.loc[played_mask, 'points_home'] = np.where(\n",
    "    data.loc[played_mask, 'home_goals_ft'] > data.loc[played_mask, 'away_goals_ft'], 3,\n",
    "    np.where(data.loc[played_mask, 'home_goals_ft'] == data.loc[played_mask, 'away_goals_ft'], 1, 0)\n",
    ")\n",
    "\n",
    "# Calculate away points for played matches only.\n",
    "data.loc[played_mask, 'points_away'] = np.where(\n",
    "    data.loc[played_mask, 'away_goals_ft'] > data.loc[played_mask, 'home_goals_ft'], 3,\n",
    "    np.where(data.loc[played_mask, 'away_goals_ft'] == data.loc[played_mask, 'home_goals_ft'], 1, 0)\n",
    ")"
   ],
   "id": "109bc350b7569bf2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:12:04.815175Z",
     "start_time": "2025-05-30T07:10:51.054736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Assign points based on match results\n",
    "# data[\"points_home\"] = data.apply(lambda row: 3 if row[\"home_goals_ft\"] > row[\"away_goals_ft\"]\n",
    "# else (1 if row[\"home_goals_ft\"] == row[\"away_goals_ft\"] else 0), axis=1)\n",
    "#\n",
    "# data[\"points_away\"] = data.apply(lambda row: 3 if row[\"away_goals_ft\"] > row[\"home_goals_ft\"]\n",
    "# else (1 if row[\"away_goals_ft\"] == row[\"home_goals_ft\"] else 0), axis=1)\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Data Preparation: Build Team-Level Data (Home & Away)\n",
    "# =============================================================================\n",
    "# Prepare home records.\n",
    "home_df = data[['country', 'season', 'date', 'home_team', 'away_team',\n",
    "                'home_goals_ft', 'away_goals_ft', 'home_goals_ht', 'away_goals_ht',\n",
    "                'shots_home', 'shots_home_1h', 'shots_home_2h',\n",
    "                'shots_on_target_home', 'shots_on_target_home_1h', 'shots_on_target_home_2h',\n",
    "                'corners_home', 'corners_home_1h', 'corners_home_2h']].copy()\n",
    "home_df.rename(columns={\n",
    "    'home_team': 'Team',\n",
    "    'away_team': 'Opponent',\n",
    "    'home_goals_ft': 'GoalsScored',\n",
    "    'away_goals_ft': 'GoalsConceded',\n",
    "    'home_goals_ht': 'FirstHalfGoalsScored',\n",
    "    'away_goals_ht': 'FirstHalfGoalsConceded',\n",
    "    'shots_home': 'Shots',\n",
    "    'shots_home_1h': 'Shots_1h',\n",
    "    'shots_home_2h': 'Shots_2h',\n",
    "    'shots_on_target_home': 'ShotsOnTarget',\n",
    "    'shots_on_target_home_1h': 'ShotsOnTarget_1h',\n",
    "    'shots_on_target_home_2h': 'ShotsOnTarget_2h',\n",
    "    'corners_home': 'Corners',\n",
    "    'corners_home_1h': 'Corners_1h',\n",
    "    'corners_home_2h': 'Corners_2h'\n",
    "}, inplace=True)\n",
    "home_df['is_home'] = 1\n",
    "\n",
    "# Prepare away records.\n",
    "away_df = data[['country', 'season', 'date', 'away_team', 'home_team',\n",
    "                'away_goals_ft', 'home_goals_ft', 'away_goals_ht', 'home_goals_ht',\n",
    "                'shots_away', 'shots_away_1h', 'shots_away_2h',\n",
    "                'shots_on_target_away', 'shots_on_target_away_1h', 'shots_on_target_away_2h',\n",
    "                'corners_away', 'corners_away_1h', 'corners_away_2h']].copy()\n",
    "away_df.rename(columns={\n",
    "    'away_team': 'Team',\n",
    "    'home_team': 'Opponent',\n",
    "    'away_goals_ft': 'GoalsScored',\n",
    "    'home_goals_ft': 'GoalsConceded',\n",
    "    'away_goals_ht': 'FirstHalfGoalsScored',\n",
    "    'home_goals_ht': 'FirstHalfGoalsConceded',\n",
    "    'shots_away': 'Shots',\n",
    "    'shots_away_1h': 'Shots_1h',\n",
    "    'shots_away_2h': 'Shots_2h',\n",
    "    'shots_on_target_away': 'ShotsOnTarget',\n",
    "    'shots_on_target_away_1h': 'ShotsOnTarget_1h',\n",
    "    'shots_on_target_away_2h': 'ShotsOnTarget_2h',\n",
    "    'corners_away': 'Corners',\n",
    "    'corners_away_1h': 'Corners_1h',\n",
    "    'corners_away_2h': 'Corners_2h'\n",
    "}, inplace=True)\n",
    "away_df['is_home'] = 0\n",
    "\n",
    "# Combine both.\n",
    "team_df = pd.concat([home_df, away_df], ignore_index=True)\n",
    "team_df.sort_values(by=['country', 'season', 'Team', 'date'], inplace=True)\n",
    "\n",
    "# Define rolling window sizes.\n",
    "window_long = 5   # for long-term trends\n",
    "window_short = 3  # for short-term momentum\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Rolling Feature Computation Functions\n",
    "# =============================================================================\n",
    "def compute_slope(x):\n",
    "    \"\"\"Compute slope using simple linear regression.\"\"\"\n",
    "    if len(x) < 2:\n",
    "        return np.nan\n",
    "    xs = np.arange(len(x))\n",
    "    return np.polyfit(xs, x, 1)[0]\n",
    "\n",
    "def compute_rolling_features_metric(df_sub, full_col, first_half_col, prefix):\n",
    "    \"\"\"\n",
    "    Compute rolling features for a given metric.\n",
    "    Returns a DataFrame of new columns.\n",
    "    \"\"\"\n",
    "    new_cols = {}\n",
    "    # Full-match features.\n",
    "    new_cols[f'{prefix}_Rolling_{full_col}_Mean'] = df_sub[full_col].rolling(window=window_long, min_periods=1).mean().shift(1)\n",
    "    new_cols[f'{prefix}_Rolling_{full_col}_Std']  = df_sub[full_col].rolling(window=window_long, min_periods=1).std().shift(1)\n",
    "    new_cols[f'{prefix}_Rolling_{full_col}_Mean_Short'] = df_sub[full_col].rolling(window=window_short, min_periods=1).mean().shift(1)\n",
    "    new_cols[f'{prefix}_Momentum_{full_col}'] = new_cols[f'{prefix}_Rolling_{full_col}_Mean_Short'] - new_cols[f'{prefix}_Rolling_{full_col}_Mean']\n",
    "    new_cols[f'{prefix}_Trend_Slope_{full_col}'] = df_sub[full_col].rolling(window=window_long, min_periods=2).apply(compute_slope, raw=True).shift(1)\n",
    "    # First-half features.\n",
    "    new_cols[f'{prefix}_Rolling_{first_half_col}_Mean'] = df_sub[first_half_col].rolling(window=window_long, min_periods=1).mean().shift(1)\n",
    "    new_cols[f'{prefix}_Rolling_{first_half_col}_Std']  = df_sub[first_half_col].rolling(window=window_long, min_periods=1).std().shift(1)\n",
    "    new_cols[f'{prefix}_Rolling_{first_half_col}_Mean_Short'] = df_sub[first_half_col].rolling(window=window_short, min_periods=1).mean().shift(1)\n",
    "    new_cols[f'{prefix}_Momentum_{first_half_col}'] = new_cols[f'{prefix}_Rolling_{first_half_col}_Mean_Short'] - new_cols[f'{prefix}_Rolling_{first_half_col}_Mean']\n",
    "    new_cols[f'{prefix}_Trend_Slope_{first_half_col}'] = df_sub[first_half_col].rolling(window=window_long, min_periods=2).apply(compute_slope, raw=True).shift(1)\n",
    "    return pd.DataFrame(new_cols, index=df_sub.index)\n",
    "\n",
    "def add_rolling_features_split(group):\n",
    "    \"\"\"Compute overall, home-, and away-specific rolling features plus outcome percentages.\"\"\"\n",
    "    group = group.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "    # Overall features.\n",
    "    overall_features = pd.concat([\n",
    "        compute_rolling_features_metric(group, 'GoalsScored', 'FirstHalfGoalsScored', 'Overall'),\n",
    "        compute_rolling_features_metric(group, 'Shots', 'Shots_1h', 'Overall'),\n",
    "        compute_rolling_features_metric(group, 'Corners', 'Corners_1h', 'Overall'),\n",
    "        compute_rolling_features_metric(group, 'ShotsOnTarget', 'ShotsOnTarget_1h', 'Overall')\n",
    "    ], axis=1)\n",
    "    group = pd.concat([group, overall_features], axis=1)\n",
    "\n",
    "    home_mask = group['is_home'] == 1\n",
    "    away_mask = group['is_home'] == 0\n",
    "\n",
    "    # Home-specific.\n",
    "    if home_mask.any():\n",
    "        home_feats = pd.concat([\n",
    "            compute_rolling_features_metric(group.loc[home_mask], 'GoalsScored', 'FirstHalfGoalsScored', 'Home'),\n",
    "            compute_rolling_features_metric(group.loc[home_mask], 'Shots', 'Shots_1h', 'Home'),\n",
    "            compute_rolling_features_metric(group.loc[home_mask], 'Corners', 'Corners_1h', 'Home'),\n",
    "            compute_rolling_features_metric(group.loc[home_mask], 'ShotsOnTarget', 'ShotsOnTarget_1h', 'Home')\n",
    "        ], axis=1)\n",
    "        group.loc[home_mask, home_feats.columns] = home_feats\n",
    "\n",
    "    # Away-specific.\n",
    "    if away_mask.any():\n",
    "        away_feats = pd.concat([\n",
    "            compute_rolling_features_metric(group.loc[away_mask], 'GoalsScored', 'FirstHalfGoalsScored', 'Away'),\n",
    "            compute_rolling_features_metric(group.loc[away_mask], 'Shots', 'Shots_1h', 'Away'),\n",
    "            compute_rolling_features_metric(group.loc[away_mask], 'Corners', 'Corners_1h', 'Away'),\n",
    "            compute_rolling_features_metric(group.loc[away_mask], 'ShotsOnTarget', 'ShotsOnTarget_1h', 'Away')\n",
    "        ], axis=1)\n",
    "        group.loc[away_mask, away_feats.columns] = away_feats\n",
    "\n",
    "    # Additional outcome percentages for goals.\n",
    "    thresh_dict = {}\n",
    "    for thresh in [1.5, 2.5, 3.5]:\n",
    "        thresh_dict[f'Overall_Percent_Over_{thresh}'] = group['GoalsScored'].gt(thresh).shift(1).expanding(min_periods=1).mean()\n",
    "        thresh_dict[f'Overall_Rolling5_Percent_Over_{thresh}'] = group['GoalsScored'].gt(thresh).shift(1).rolling(window=5, min_periods=1).mean()\n",
    "        if home_mask.any():\n",
    "            thresh_dict[f'Home_Percent_Over_{thresh}'] = group.loc[home_mask, 'GoalsScored'].gt(thresh).shift(1).expanding(min_periods=1).mean()\n",
    "            thresh_dict[f'Home_Rolling5_Percent_Over_{thresh}'] = group.loc[home_mask, 'GoalsScored'].gt(thresh).shift(1).rolling(window=5, min_periods=1).mean()\n",
    "        if away_mask.any():\n",
    "            thresh_dict[f'Away_Percent_Over_{thresh}'] = group.loc[away_mask, 'GoalsScored'].gt(thresh).shift(1).expanding(min_periods=1).mean()\n",
    "            thresh_dict[f'Away_Rolling5_Percent_Over_{thresh}'] = group.loc[away_mask, 'GoalsScored'].gt(thresh).shift(1).rolling(window=5, min_periods=1).mean()\n",
    "    group = pd.concat([group, pd.DataFrame(thresh_dict, index=group.index)], axis=1)\n",
    "\n",
    "    # Outcome percentages for goals.\n",
    "    outcome_dict = {}\n",
    "    for thresh in [0.5, 1.5, 2.5, 3.5]:\n",
    "        outcome_dict[f'TeamPct_Over_{thresh}'] = group['GoalsScored'].gt(thresh).shift(1).expanding(min_periods=1).mean()\n",
    "        if home_mask.any():\n",
    "            outcome_dict[f'Home_TeamPct_Over_{thresh}'] = group.loc[home_mask, 'GoalsScored'].gt(thresh).shift(1).expanding(min_periods=1).mean()\n",
    "        if away_mask.any():\n",
    "            outcome_dict[f'Away_TeamPct_Over_{thresh}'] = group.loc[away_mask, 'GoalsScored'].gt(thresh).shift(1).expanding(min_periods=1).mean()\n",
    "    group = pd.concat([group, pd.DataFrame(outcome_dict, index=group.index)], axis=1)\n",
    "\n",
    "    # Outcome percentages for corners.\n",
    "    corners_thresh = [3.5, 4.5, 5.5, 6.5]\n",
    "    corners_dict = {}\n",
    "    for thresh in corners_thresh:\n",
    "        corners_dict[f'CornersPct_Over_{thresh}'] = group['Corners'].gt(thresh).shift(1).expanding(min_periods=1).mean()\n",
    "        corners_dict[f'CornersRolling5Pct_Over_{thresh}'] = group['Corners'].gt(thresh).shift(1).rolling(window=5, min_periods=1).mean()\n",
    "        if home_mask.any():\n",
    "            corners_dict[f'Home_CornersPct_Over_{thresh}'] = group.loc[home_mask, 'Corners'].gt(thresh).shift(1).expanding(min_periods=1).mean()\n",
    "            corners_dict[f'Home_CornersRolling5Pct_Over_{thresh}'] = group.loc[home_mask, 'Corners'].gt(thresh).shift(1).rolling(window=5, min_periods=1).mean()\n",
    "        if away_mask.any():\n",
    "            corners_dict[f'Away_CornersPct_Over_{thresh}'] = group.loc[away_mask, 'Corners'].gt(thresh).shift(1).expanding(min_periods=1).mean()\n",
    "            corners_dict[f'Away_CornersRolling5Pct_Over_{thresh}'] = group.loc[away_mask, 'Corners'].gt(thresh).shift(1).rolling(window=5, min_periods=1).mean()\n",
    "    group = pd.concat([group, pd.DataFrame(corners_dict, index=group.index)], axis=1)\n",
    "\n",
    "    return group\n",
    "\n",
    "# Apply group-wise computations.\n",
    "team_df = team_df.groupby(['country', 'season', 'Team'], group_keys=False).apply(add_rolling_features_split).reset_index(drop=True)\n",
    "team_df = team_df.copy()  # ensure defragmentation\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Compute Team-Level Corners Outcome Features (from Match Data)\n",
    "# =============================================================================\n",
    "# Build a match-level DataFrame for corners outcomes.\n",
    "match_df = data.copy()\n",
    "match_df['Total_Corners'] = match_df['corners_home'] + match_df['corners_away']\n",
    "match_df.sort_values(by=['country', 'season', 'date'], inplace=True)\n",
    "\n",
    "# Create a team perspective by combining home and away records.\n",
    "home_matches = match_df[['country', 'season', 'date', 'home_team', 'Total_Corners']].copy()\n",
    "home_matches.rename(columns={'home_team': 'Team'}, inplace=True)\n",
    "away_matches = match_df[['country', 'season', 'date', 'away_team', 'Total_Corners']].copy()\n",
    "away_matches.rename(columns={'away_team': 'Team'}, inplace=True)\n",
    "team_corners_matches = pd.concat([home_matches, away_matches], ignore_index=True)\n",
    "team_corners_matches.sort_values(by=['country', 'season', 'Team', 'date'], inplace=True)\n",
    "\n",
    "# For thresholds 9.5, 10.5, and 11.5, compute season-level and rolling percentages.\n",
    "for thr in [9.5, 10.5, 11.5]:\n",
    "    indicator = f'Over_{thr}'\n",
    "    team_corners_matches[indicator] = (team_corners_matches['Total_Corners'] > thr).astype(int)\n",
    "    team_corners_matches[f'SeasonPct_{indicator}'] = team_corners_matches.groupby(\n",
    "        ['country', 'season', 'Team']\n",
    "    )[indicator].transform(lambda x: x.shift(1).expanding(min_periods=1).mean())\n",
    "    team_corners_matches[f'Rolling5Pct_{indicator}'] = team_corners_matches.groupby(\n",
    "        ['country', 'season', 'Team']\n",
    "    )[indicator].transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())\n",
    "\n",
    "# Select only the keys and outcome columns for merging.\n",
    "cols_to_merge = ['country', 'season', 'date', 'Team',\n",
    "                 'SeasonPct_Over_9.5', 'Rolling5Pct_Over_9.5',\n",
    "                 'SeasonPct_Over_10.5', 'Rolling5Pct_Over_10.5',\n",
    "                 'SeasonPct_Over_11.5', 'Rolling5Pct_Over_11.5']\n",
    "\n",
    "# Merge the corners outcome features into team_df.\n",
    "team_df = team_df.merge(team_corners_matches[cols_to_merge],\n",
    "                        on=['country', 'season', 'date', 'Team'],\n",
    "                        how='left')\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Process Home and Away Features for Match-Level Merging\n",
    "# =============================================================================\n",
    "# -- Home-Team Process --\n",
    "home_subset = team_df[team_df['is_home'] == 1].copy()\n",
    "home_subset.drop(columns=['Opponent'], inplace=True)\n",
    "home_subset.rename(columns={'Team': 'home_team'}, inplace=True)\n",
    "home_key = ['country', 'season', 'date', 'home_team', 'is_home']\n",
    "# Include features starting with Overall_, Home_, SeasonPct_Over_, or Rolling5Pct_Over_\n",
    "home_feats = [col for col in home_subset.columns if col not in home_key and\n",
    "              (col.startswith(\"Overall_\") or col.startswith(\"Home_\") or\n",
    "               col.startswith(\"SeasonPct_Over_\") or col.startswith(\"Rolling5Pct_Over_\"))]\n",
    "home_features = home_subset[home_key + home_feats].copy()\n",
    "def clean_home_name(col):\n",
    "    return \"home_\" + (col[len(\"Home_\"):] if col.startswith(\"Home_\") else col)\n",
    "home_features.rename(columns={col: clean_home_name(col) for col in home_feats}, inplace=True)\n",
    "\n",
    "# -- Away-Team Process --\n",
    "away_subset = team_df[team_df['is_home'] == 0].copy()\n",
    "away_subset.drop(columns=['Opponent'], inplace=True)\n",
    "away_subset.rename(columns={'Team': 'away_team'}, inplace=True)\n",
    "away_key = ['country', 'season', 'date', 'away_team', 'is_home']\n",
    "away_feats = [col for col in away_subset.columns if col not in away_key and\n",
    "              (col.startswith(\"Overall_\") or col.startswith(\"Away_\") or\n",
    "               col.startswith(\"SeasonPct_Over_\") or col.startswith(\"Rolling5Pct_Over_\"))]\n",
    "away_features = away_subset[away_key + away_feats].copy()\n",
    "def clean_away_name(col):\n",
    "    return \"away_\" + (col[len(\"Away_\"):] if col.startswith(\"Away_\") else col)\n",
    "away_features.rename(columns={col: clean_away_name(col) for col in away_feats}, inplace=True)\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Merge Home and Away Features into the Match-Level DataFrame\n",
    "# =============================================================================\n",
    "# Start with the original match data.\n",
    "match_merge_df = data.copy()\n",
    "# Merge home features.\n",
    "match_merge_df = match_merge_df.merge(home_features, on=['country', 'season', 'date', 'home_team'], how='left')\n",
    "# Merge away features.\n",
    "match_merge_df = match_merge_df.merge(away_features, on=['country', 'season', 'date', 'away_team'], how='left')\n",
    "\n",
    "# (Optional) Display a sample.\n",
    "#print(match_merge_df.head())\n"
   ],
   "id": "c555cf3374e982c3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leere\\AppData\\Local\\Temp\\ipykernel_17368\\3827831954.py:175: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  team_df = team_df.groupby(['country', 'season', 'Team'], group_keys=False).apply(add_rolling_features_split).reset_index(drop=True)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:12:04.903615Z",
     "start_time": "2025-05-30T07:12:04.899686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# match_merge_df_filter = match_merge_df[match_merge_df['away_team'] == \"Chelsea\"]\n",
    "# match_merge_df_filter"
   ],
   "id": "5438733d5984f63",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:12:05.080627Z",
     "start_time": "2025-05-30T07:12:04.923720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## -----------------------------\n",
    "# 1. Process Home-Team Features (with clean naming)\n",
    "# -----------------------------\n",
    "home_subset = team_df[team_df['is_home'] == 1].copy()\n",
    "home_subset = home_subset.drop(columns=['Opponent'])\n",
    "home_subset.rename(columns={'Team': 'home_team'}, inplace=True)\n",
    "\n",
    "# Key columns that remain unchanged\n",
    "home_key_cols = ['country', 'season', 'date', 'home_team', 'is_home']\n",
    "\n",
    "# Update the feature column selection to include the merged outcome columns.\n",
    "home_feature_cols = [col for col in home_subset.columns\n",
    "                     if col not in home_key_cols and\n",
    "                     (col.startswith(\"Overall_\") or\n",
    "                      col.startswith(\"Home_\") or\n",
    "                      col.startswith(\"SeasonPct_Over_\") or\n",
    "                      col.startswith(\"Rolling5Pct_Over_\"))]\n",
    "\n",
    "# Create a DataFrame with key columns and desired features\n",
    "home_features = home_subset[home_key_cols + home_feature_cols].copy()\n",
    "\n",
    "# Function to clean column names by removing any existing \"Home_\" prefix\n",
    "def clean_home_name(col):\n",
    "    if col.startswith(\"Home_\"):\n",
    "        col = col[len(\"Home_\"):]\n",
    "    return \"home_\" + col\n",
    "\n",
    "# Build a renaming dictionary for home features\n",
    "rename_mapping_home = {col: clean_home_name(col) for col in home_feature_cols}\n",
    "home_features.rename(columns=rename_mapping_home, inplace=True)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Process Away-Team Features (with clean naming)\n",
    "# -----------------------------\n",
    "away_subset = team_df[team_df['is_home'] == 0].copy()\n",
    "away_subset = away_subset.drop(columns=['Opponent'])\n",
    "away_subset.rename(columns={'Team': 'away_team'}, inplace=True)\n",
    "\n",
    "# Key columns that remain unchanged\n",
    "away_key_cols = ['country', 'season', 'date', 'away_team', 'is_home']\n",
    "\n",
    "# Update the feature column selection to include the merged outcome columns.\n",
    "away_feature_cols = [col for col in away_subset.columns\n",
    "                     if col not in away_key_cols and\n",
    "                     (col.startswith(\"Overall_\") or\n",
    "                      col.startswith(\"Away_\") or\n",
    "                      col.startswith(\"SeasonPct_Over_\") or\n",
    "                      col.startswith(\"Rolling5Pct_Over_\"))]\n",
    "\n",
    "# Create a DataFrame with key columns and desired features\n",
    "away_features = away_subset[away_key_cols + away_feature_cols].copy()\n",
    "\n",
    "# Function to clean column names by removing any existing \"Away_\" prefix\n",
    "def clean_away_name(col):\n",
    "    if col.startswith(\"Away_\"):\n",
    "        col = col[len(\"Away_\"):]\n",
    "    return \"away_\" + col\n",
    "\n",
    "# Build a renaming dictionary for away features\n",
    "rename_mapping_away = {col: clean_away_name(col) for col in away_feature_cols}\n",
    "away_features.rename(columns=rename_mapping_away, inplace=True)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Merge Processed Home- and Away-Team Features Back into the Match-Level DataFrame\n",
    "# -----------------------------\n",
    "# Start with your original match-level data\n",
    "match_df = data.copy()\n",
    "\n",
    "# Merge home features on the common keys: country, season, date, and home_team.\n",
    "match_df = match_df.merge(home_features, on=['country', 'season', 'date', 'home_team'], how='left')\n",
    "\n",
    "#Merge away features on the common keys: country, season, date, and away_team.\n",
    "match_df = match_df.merge(away_features, on=['country', 'season', 'date', 'away_team'], how='left')\n",
    "\n",
    "# # match_df now contains cleanly named columns such as \"home_Rolling_GoalsScored_Mean\" along with your corners outcome features.\n",
    "# print(match_df.head())\n"
   ],
   "id": "8a13f3a00e8cae08",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:12:05.135645Z",
     "start_time": "2025-05-30T07:12:05.132720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# team_filter2 = match_df[(match_df[\"home_team\"]==\"Chelsea\") | (match_df[\"away_team\"]==\"Chelsea\")]\n",
    "# team_filter2"
   ],
   "id": "69ab734aa4dd22a9",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:12:05.240083Z",
     "start_time": "2025-05-30T07:12:05.236126Z"
    }
   },
   "cell_type": "code",
   "source": "#match_df",
   "id": "bae1732432ec380b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:12:05.259368Z",
     "start_time": "2025-05-30T07:12:05.250175Z"
    }
   },
   "cell_type": "code",
   "source": "features = ['round', 'home_team_place_total', 'home_team_place_home', 'away_team_place_total', 'away_team_place_away', 'home_odds', 'draw_odds', 'away_odds', 'over_25_odds', 'under_25_odds', 'elo_home', 'elo_away', 'form_home', 'form_away', 'home_Overall_Rolling_GoalsScored_Mean', 'home_Overall_Rolling_GoalsScored_Std', 'home_Overall_Rolling_GoalsScored_Mean_Short', 'home_Overall_Momentum_GoalsScored', 'home_Overall_Trend_Slope_GoalsScored', 'home_Overall_Rolling_FirstHalfGoalsScored_Mean', 'home_Overall_Rolling_FirstHalfGoalsScored_Std', 'home_Overall_Rolling_FirstHalfGoalsScored_Mean_Short', 'home_Overall_Momentum_FirstHalfGoalsScored', 'home_Overall_Trend_Slope_FirstHalfGoalsScored', 'home_Overall_Rolling_Shots_Mean', 'home_Overall_Rolling_Shots_Std', 'home_Overall_Rolling_Shots_Mean_Short', 'home_Overall_Momentum_Shots', 'home_Overall_Trend_Slope_Shots', 'home_Overall_Rolling_Shots_1h_Mean', 'home_Overall_Rolling_Shots_1h_Std', 'home_Overall_Rolling_Shots_1h_Mean_Short', 'home_Overall_Momentum_Shots_1h', 'home_Overall_Trend_Slope_Shots_1h', 'home_Overall_Rolling_Corners_Mean', 'home_Overall_Rolling_Corners_Std', 'home_Overall_Rolling_Corners_Mean_Short', 'home_Overall_Momentum_Corners', 'home_Overall_Trend_Slope_Corners', 'home_Overall_Rolling_Corners_1h_Mean', 'home_Overall_Rolling_Corners_1h_Std', 'home_Overall_Rolling_Corners_1h_Mean_Short', 'home_Overall_Momentum_Corners_1h', 'home_Overall_Trend_Slope_Corners_1h', 'home_Overall_Rolling_ShotsOnTarget_Mean', 'home_Overall_Rolling_ShotsOnTarget_Std', 'home_Overall_Rolling_ShotsOnTarget_Mean_Short', 'home_Overall_Momentum_ShotsOnTarget', 'home_Overall_Trend_Slope_ShotsOnTarget', 'home_Overall_Rolling_ShotsOnTarget_1h_Mean', 'home_Overall_Rolling_ShotsOnTarget_1h_Std', 'home_Overall_Rolling_ShotsOnTarget_1h_Mean_Short', 'home_Overall_Momentum_ShotsOnTarget_1h', 'home_Overall_Trend_Slope_ShotsOnTarget_1h', 'home_Rolling_GoalsScored_Mean', 'home_Rolling_GoalsScored_Std', 'home_Rolling_GoalsScored_Mean_Short', 'home_Momentum_GoalsScored', 'home_Trend_Slope_GoalsScored', 'home_Rolling_FirstHalfGoalsScored_Mean', 'home_Rolling_FirstHalfGoalsScored_Std', 'home_Rolling_FirstHalfGoalsScored_Mean_Short', 'home_Momentum_FirstHalfGoalsScored', 'home_Trend_Slope_FirstHalfGoalsScored', 'home_Rolling_Shots_Mean', 'home_Rolling_Shots_Std', 'home_Rolling_Shots_Mean_Short', 'home_Momentum_Shots', 'home_Trend_Slope_Shots', 'home_Rolling_Shots_1h_Mean', 'home_Rolling_Shots_1h_Std', 'home_Rolling_Shots_1h_Mean_Short', 'home_Momentum_Shots_1h', 'home_Trend_Slope_Shots_1h', 'home_Rolling_Corners_Mean', 'home_Rolling_Corners_Std', 'home_Rolling_Corners_Mean_Short', 'home_Momentum_Corners', 'home_Trend_Slope_Corners', 'home_Rolling_Corners_1h_Mean', 'home_Rolling_Corners_1h_Std', 'home_Rolling_Corners_1h_Mean_Short', 'home_Momentum_Corners_1h', 'home_Trend_Slope_Corners_1h', 'home_Rolling_ShotsOnTarget_Mean', 'home_Rolling_ShotsOnTarget_Std', 'home_Rolling_ShotsOnTarget_Mean_Short', 'home_Momentum_ShotsOnTarget', 'home_Trend_Slope_ShotsOnTarget', 'home_Rolling_ShotsOnTarget_1h_Mean', 'home_Rolling_ShotsOnTarget_1h_Std', 'home_Rolling_ShotsOnTarget_1h_Mean_Short', 'home_Momentum_ShotsOnTarget_1h', 'home_Trend_Slope_ShotsOnTarget_1h', 'home_Overall_Percent_Over_1.5', 'home_Overall_Rolling5_Percent_Over_1.5', 'home_Percent_Over_1.5', 'home_Rolling5_Percent_Over_1.5', 'home_Overall_Percent_Over_2.5', 'home_Overall_Rolling5_Percent_Over_2.5', 'home_Percent_Over_2.5', 'home_Rolling5_Percent_Over_2.5', 'home_Overall_Percent_Over_3.5', 'home_Overall_Rolling5_Percent_Over_3.5', 'home_Percent_Over_3.5', 'home_Rolling5_Percent_Over_3.5', 'home_TeamPct_Over_0.5', 'home_TeamPct_Over_1.5', 'home_TeamPct_Over_2.5', 'home_TeamPct_Over_3.5', 'home_CornersPct_Over_3.5', 'home_CornersRolling5Pct_Over_3.5', 'home_CornersPct_Over_4.5', 'home_CornersRolling5Pct_Over_4.5', 'home_CornersPct_Over_5.5', 'home_CornersRolling5Pct_Over_5.5', 'home_CornersPct_Over_6.5', 'home_CornersRolling5Pct_Over_6.5', 'home_SeasonPct_Over_9.5', 'home_Rolling5Pct_Over_9.5', 'home_SeasonPct_Over_10.5', 'home_Rolling5Pct_Over_10.5', 'home_SeasonPct_Over_11.5', 'home_Rolling5Pct_Over_11.5', 'away_Overall_Rolling_GoalsScored_Mean', 'away_Overall_Rolling_GoalsScored_Std', 'away_Overall_Rolling_GoalsScored_Mean_Short', 'away_Overall_Momentum_GoalsScored', 'away_Overall_Trend_Slope_GoalsScored', 'away_Overall_Rolling_FirstHalfGoalsScored_Mean', 'away_Overall_Rolling_FirstHalfGoalsScored_Std', 'away_Overall_Rolling_FirstHalfGoalsScored_Mean_Short', 'away_Overall_Momentum_FirstHalfGoalsScored', 'away_Overall_Trend_Slope_FirstHalfGoalsScored', 'away_Overall_Rolling_Shots_Mean', 'away_Overall_Rolling_Shots_Std', 'away_Overall_Rolling_Shots_Mean_Short', 'away_Overall_Momentum_Shots', 'away_Overall_Trend_Slope_Shots', 'away_Overall_Rolling_Shots_1h_Mean', 'away_Overall_Rolling_Shots_1h_Std', 'away_Overall_Rolling_Shots_1h_Mean_Short', 'away_Overall_Momentum_Shots_1h', 'away_Overall_Trend_Slope_Shots_1h', 'away_Overall_Rolling_Corners_Mean', 'away_Overall_Rolling_Corners_Std', 'away_Overall_Rolling_Corners_Mean_Short', 'away_Overall_Momentum_Corners', 'away_Overall_Trend_Slope_Corners', 'away_Overall_Rolling_Corners_1h_Mean', 'away_Overall_Rolling_Corners_1h_Std', 'away_Overall_Rolling_Corners_1h_Mean_Short', 'away_Overall_Momentum_Corners_1h', 'away_Overall_Trend_Slope_Corners_1h', 'away_Overall_Rolling_ShotsOnTarget_Mean', 'away_Overall_Rolling_ShotsOnTarget_Std', 'away_Overall_Rolling_ShotsOnTarget_Mean_Short', 'away_Overall_Momentum_ShotsOnTarget', 'away_Overall_Trend_Slope_ShotsOnTarget', 'away_Overall_Rolling_ShotsOnTarget_1h_Mean', 'away_Overall_Rolling_ShotsOnTarget_1h_Std', 'away_Overall_Rolling_ShotsOnTarget_1h_Mean_Short', 'away_Overall_Momentum_ShotsOnTarget_1h', 'away_Overall_Trend_Slope_ShotsOnTarget_1h', 'away_Rolling_GoalsScored_Mean', 'away_Rolling_GoalsScored_Std', 'away_Rolling_GoalsScored_Mean_Short', 'away_Momentum_GoalsScored', 'away_Trend_Slope_GoalsScored', 'away_Rolling_FirstHalfGoalsScored_Mean', 'away_Rolling_FirstHalfGoalsScored_Std', 'away_Rolling_FirstHalfGoalsScored_Mean_Short', 'away_Momentum_FirstHalfGoalsScored', 'away_Trend_Slope_FirstHalfGoalsScored', 'away_Rolling_Shots_Mean', 'away_Rolling_Shots_Std', 'away_Rolling_Shots_Mean_Short', 'away_Momentum_Shots', 'away_Trend_Slope_Shots', 'away_Rolling_Shots_1h_Mean', 'away_Rolling_Shots_1h_Std', 'away_Rolling_Shots_1h_Mean_Short', 'away_Momentum_Shots_1h', 'away_Trend_Slope_Shots_1h', 'away_Rolling_Corners_Mean', 'away_Rolling_Corners_Std', 'away_Rolling_Corners_Mean_Short', 'away_Momentum_Corners', 'away_Trend_Slope_Corners', 'away_Rolling_Corners_1h_Mean', 'away_Rolling_Corners_1h_Std', 'away_Rolling_Corners_1h_Mean_Short', 'away_Momentum_Corners_1h', 'away_Trend_Slope_Corners_1h', 'away_Rolling_ShotsOnTarget_Mean', 'away_Rolling_ShotsOnTarget_Std', 'away_Rolling_ShotsOnTarget_Mean_Short', 'away_Momentum_ShotsOnTarget', 'away_Trend_Slope_ShotsOnTarget', 'away_Rolling_ShotsOnTarget_1h_Mean', 'away_Rolling_ShotsOnTarget_1h_Std', 'away_Rolling_ShotsOnTarget_1h_Mean_Short', 'away_Momentum_ShotsOnTarget_1h', 'away_Trend_Slope_ShotsOnTarget_1h', 'away_Overall_Percent_Over_1.5', 'away_Overall_Rolling5_Percent_Over_1.5', 'away_Percent_Over_1.5', 'away_Rolling5_Percent_Over_1.5', 'away_Overall_Percent_Over_2.5', 'away_Overall_Rolling5_Percent_Over_2.5', 'away_Percent_Over_2.5', 'away_Rolling5_Percent_Over_2.5', 'away_Overall_Percent_Over_3.5', 'away_Overall_Rolling5_Percent_Over_3.5', 'away_Percent_Over_3.5', 'away_Rolling5_Percent_Over_3.5', 'away_TeamPct_Over_0.5', 'away_TeamPct_Over_1.5', 'away_TeamPct_Over_2.5', 'away_TeamPct_Over_3.5', 'away_CornersPct_Over_3.5', 'away_CornersRolling5Pct_Over_3.5', 'away_CornersPct_Over_4.5', 'away_CornersRolling5Pct_Over_4.5', 'away_CornersPct_Over_5.5', 'away_CornersRolling5Pct_Over_5.5', 'away_CornersPct_Over_6.5', 'away_CornersRolling5Pct_Over_6.5', 'away_SeasonPct_Over_9.5', 'away_Rolling5Pct_Over_9.5', 'away_SeasonPct_Over_10.5', 'away_Rolling5Pct_Over_10.5', 'away_SeasonPct_Over_11.5', 'away_Rolling5Pct_Over_11.5', 'country_Arg1', 'country_Aus1', 'country_Aus2', 'country_Aut1', 'country_Bel1', 'country_Bra1', 'country_Bul1', 'country_Chi1', 'country_Chl1', 'country_Cro1', 'country_Czh1', 'country_Den1', 'country_Eng1', 'country_Eng2', 'country_Eng3', 'country_Eng4', 'country_Fra1', 'country_Fra2', 'country_Ger1', 'country_Ger2', 'country_Ger3', 'country_Gre1', 'country_Hun1', 'country_Ice1', 'country_Ire1', 'country_Isr1', 'country_Ita1', 'country_Ita2', 'country_Jap1', 'country_Jap2', 'country_Kor1', 'country_Mex1', 'country_Ned1', 'country_Ned2', 'country_Nor1', 'country_Pol1', 'country_Por1', 'country_Rom1', 'country_Sco1', 'country_Sco2', 'country_Slk1', 'country_Slo1', 'country_Spa1', 'country_Spa2', 'country_Swe1', 'country_Swe2', 'country_Swi1', 'country_Swi2', 'country_Tur1', 'country_Tur2', 'country_USA1', 'country_Arg1', 'country_Aus1', 'country_Aus2', 'country_Aut1', 'country_Bel1', 'country_Bra1', 'country_Bul1', 'country_Chi1', 'country_Chl1', 'country_Cro1', 'country_Czh1', 'country_Den1', 'country_Eng1', 'country_Eng2', 'country_Eng3', 'country_Eng4', 'country_Fra1', 'country_Fra2', 'country_Ger1', 'country_Ger2', 'country_Ger3', 'country_Gre1', 'country_Hun1', 'country_Ice1', 'country_Ire1', 'country_Isr1', 'country_Ita1', 'country_Ita2', 'country_Jap1', 'country_Jap2', 'country_Kor1', 'country_Mex1', 'country_Ned1', 'country_Ned2', 'country_Nor1', 'country_Pol1', 'country_Por1', 'country_Rom1', 'country_Sco1', 'country_Sco2', 'country_Slk1', 'country_Slo1', 'country_Spa1', 'country_Spa2', 'country_Swe1', 'country_Swe2', 'country_Swi1', 'country_Swi2', 'country_Tur1', 'country_Tur2', 'country_USA1']",
   "id": "ed2a26038c07c55c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:12:12.779265Z",
     "start_time": "2025-05-30T07:12:05.311214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import function_library as fl\n",
    "filtered_data = match_df[(match_df['date'].dt.date >= today) & (match_df['date'].dt.date <= end_period)].copy()\n",
    "filtered_data = fl.team_name_map(filtered_data)\n",
    "filtered_data"
   ],
   "id": "57d97dba479369bb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      country  season       date  ko_time  round     home_team     away_team  \\\n",
       "12425    Tur1      25 2025-05-30     1800     38   Galatasaray    Basaksehir   \n",
       "12426    Tur1      25 2025-05-30     1800     38   Antalyaspor   Trabzonspor   \n",
       "12427    Swe2      25 2025-05-30     1800     11        Orebro         Brage   \n",
       "12428    Ire1      25 2025-05-30     2000     18      Shamrock    Galway Utd   \n",
       "12429    Tur1      25 2025-05-30     1800     38     Kasimpasa       Goztepe   \n",
       "...       ...     ...        ...      ...    ...           ...           ...   \n",
       "12530    Swe2      25 2025-06-01     1400     11  Helsingborgs  Ostersund FK   \n",
       "12531    Swe1      25 2025-06-01     1530     12        Sirius           AIK   \n",
       "12532    Swe1      25 2025-06-01     1530     12       Mjallby       Varnamo   \n",
       "12533    Swe1      25 2025-06-01     1300     12      Malmo FF        Hacken   \n",
       "12534    Swe2      25 2025-06-01     1600     11      Oddevold    Landskrona   \n",
       "\n",
       "       home_goals_ft  away_goals_ft  home_goals_ht  ...  \\\n",
       "12425              0              0              0  ...   \n",
       "12426              0              0              0  ...   \n",
       "12427              0              0              0  ...   \n",
       "12428              0              0              0  ...   \n",
       "12429              0              0              0  ...   \n",
       "...              ...            ...            ...  ...   \n",
       "12530              0              0              0  ...   \n",
       "12531              0              0              0  ...   \n",
       "12532              0              0              0  ...   \n",
       "12533              0              0              0  ...   \n",
       "12534              0              0              0  ...   \n",
       "\n",
       "       away_CornersPct_Over_5.5  away_CornersRolling5Pct_Over_5.5  \\\n",
       "12425                  0.294118                               0.4   \n",
       "12426                  0.294118                               0.0   \n",
       "12427                  0.000000                               0.0   \n",
       "12428                  0.375000                               0.4   \n",
       "12429                  0.176471                               0.2   \n",
       "...                         ...                               ...   \n",
       "12530                  0.000000                               0.0   \n",
       "12531                  0.571429                               0.6   \n",
       "12532                  0.600000                               0.6   \n",
       "12533                  0.200000                               0.2   \n",
       "12534                  0.000000                               0.0   \n",
       "\n",
       "       away_CornersPct_Over_6.5  away_CornersRolling5Pct_Over_6.5  \\\n",
       "12425                  0.176471                               0.2   \n",
       "12426                  0.235294                               0.0   \n",
       "12427                  0.000000                               0.0   \n",
       "12428                  0.250000                               0.4   \n",
       "12429                  0.000000                               0.0   \n",
       "...                         ...                               ...   \n",
       "12530                  0.000000                               0.0   \n",
       "12531                  0.428571                               0.4   \n",
       "12532                  0.400000                               0.4   \n",
       "12533                  0.200000                               0.2   \n",
       "12534                  0.000000                               0.0   \n",
       "\n",
       "       away_SeasonPct_Over_9.5  away_Rolling5Pct_Over_9.5  \\\n",
       "12425                 0.400000                        0.8   \n",
       "12426                 0.457143                        0.6   \n",
       "12427                 0.000000                        0.0   \n",
       "12428                 0.529412                        0.6   \n",
       "12429                 0.428571                        0.6   \n",
       "...                        ...                        ...   \n",
       "12530                 0.000000                        0.0   \n",
       "12531                 0.750000                        0.8   \n",
       "12532                 0.545455                        0.4   \n",
       "12533                 0.545455                        0.2   \n",
       "12534                 0.000000                        0.0   \n",
       "\n",
       "       away_SeasonPct_Over_10.5  away_Rolling5Pct_Over_10.5  \\\n",
       "12425                  0.257143                         0.4   \n",
       "12426                  0.342857                         0.4   \n",
       "12427                  0.000000                         0.0   \n",
       "12428                  0.411765                         0.6   \n",
       "12429                  0.228571                         0.6   \n",
       "...                         ...                         ...   \n",
       "12530                  0.000000                         0.0   \n",
       "12531                  0.583333                         0.6   \n",
       "12532                  0.545455                         0.4   \n",
       "12533                  0.454545                         0.2   \n",
       "12534                  0.000000                         0.0   \n",
       "\n",
       "       away_SeasonPct_Over_11.5  away_Rolling5Pct_Over_11.5  \n",
       "12425                  0.171429                         0.0  \n",
       "12426                  0.257143                         0.4  \n",
       "12427                  0.000000                         0.0  \n",
       "12428                  0.294118                         0.4  \n",
       "12429                  0.142857                         0.4  \n",
       "...                         ...                         ...  \n",
       "12530                  0.000000                         0.0  \n",
       "12531                  0.416667                         0.4  \n",
       "12532                  0.454545                         0.4  \n",
       "12533                  0.454545                         0.2  \n",
       "12534                  0.000000                         0.0  \n",
       "\n",
       "[110 rows x 284 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>season</th>\n",
       "      <th>date</th>\n",
       "      <th>ko_time</th>\n",
       "      <th>round</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_goals_ft</th>\n",
       "      <th>away_goals_ft</th>\n",
       "      <th>home_goals_ht</th>\n",
       "      <th>...</th>\n",
       "      <th>away_CornersPct_Over_5.5</th>\n",
       "      <th>away_CornersRolling5Pct_Over_5.5</th>\n",
       "      <th>away_CornersPct_Over_6.5</th>\n",
       "      <th>away_CornersRolling5Pct_Over_6.5</th>\n",
       "      <th>away_SeasonPct_Over_9.5</th>\n",
       "      <th>away_Rolling5Pct_Over_9.5</th>\n",
       "      <th>away_SeasonPct_Over_10.5</th>\n",
       "      <th>away_Rolling5Pct_Over_10.5</th>\n",
       "      <th>away_SeasonPct_Over_11.5</th>\n",
       "      <th>away_Rolling5Pct_Over_11.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12425</th>\n",
       "      <td>Tur1</td>\n",
       "      <td>25</td>\n",
       "      <td>2025-05-30</td>\n",
       "      <td>1800</td>\n",
       "      <td>38</td>\n",
       "      <td>Galatasaray</td>\n",
       "      <td>Basaksehir</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12426</th>\n",
       "      <td>Tur1</td>\n",
       "      <td>25</td>\n",
       "      <td>2025-05-30</td>\n",
       "      <td>1800</td>\n",
       "      <td>38</td>\n",
       "      <td>Antalyaspor</td>\n",
       "      <td>Trabzonspor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12427</th>\n",
       "      <td>Swe2</td>\n",
       "      <td>25</td>\n",
       "      <td>2025-05-30</td>\n",
       "      <td>1800</td>\n",
       "      <td>11</td>\n",
       "      <td>Orebro</td>\n",
       "      <td>Brage</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12428</th>\n",
       "      <td>Ire1</td>\n",
       "      <td>25</td>\n",
       "      <td>2025-05-30</td>\n",
       "      <td>2000</td>\n",
       "      <td>18</td>\n",
       "      <td>Shamrock</td>\n",
       "      <td>Galway Utd</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12429</th>\n",
       "      <td>Tur1</td>\n",
       "      <td>25</td>\n",
       "      <td>2025-05-30</td>\n",
       "      <td>1800</td>\n",
       "      <td>38</td>\n",
       "      <td>Kasimpasa</td>\n",
       "      <td>Goztepe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12530</th>\n",
       "      <td>Swe2</td>\n",
       "      <td>25</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>1400</td>\n",
       "      <td>11</td>\n",
       "      <td>Helsingborgs</td>\n",
       "      <td>Ostersund FK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12531</th>\n",
       "      <td>Swe1</td>\n",
       "      <td>25</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>1530</td>\n",
       "      <td>12</td>\n",
       "      <td>Sirius</td>\n",
       "      <td>AIK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12532</th>\n",
       "      <td>Swe1</td>\n",
       "      <td>25</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>1530</td>\n",
       "      <td>12</td>\n",
       "      <td>Mjallby</td>\n",
       "      <td>Varnamo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12533</th>\n",
       "      <td>Swe1</td>\n",
       "      <td>25</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>1300</td>\n",
       "      <td>12</td>\n",
       "      <td>Malmo FF</td>\n",
       "      <td>Hacken</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12534</th>\n",
       "      <td>Swe2</td>\n",
       "      <td>25</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>1600</td>\n",
       "      <td>11</td>\n",
       "      <td>Oddevold</td>\n",
       "      <td>Landskrona</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows Ã— 284 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:12:12.902492Z",
     "start_time": "2025-05-30T07:12:12.895929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import pandas as pd\n",
    "# from joblib import load\n",
    "# import function_library as fl\n",
    "#\n",
    "# # â”€â”€ CONFIGURATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MODEL_DIR   = r\"C:\\Users\\leere\\PycharmProjects\\Football_ML3\\Goals\\2H_goal\\ht_scoreline\\path_ht_score\\to\\save\\models\"\n",
    "# fixtures_df = filtered_data.copy()   # upcoming fixtures, must include raw features + 'country'\n",
    "# market_map  = {\n",
    "#     \"0-0\": 0.5, \"0-1\": 1.5, \"1-0\": 1.5, \"1-1\": 1.5,\n",
    "#     \"0-2\": 2.5, \"2-0\": 2.5, \"2-1\": 3.5, \"1-2\": 3.5,\n",
    "#     \"3-0\": 3.5,\n",
    "# }\n",
    "#\n",
    "# # â”€â”€ PREDICTION LOOP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# for scoreline, market_line in market_map.items():\n",
    "#     # a) Tag every fixture with this hypothetical HT score\n",
    "#     df_sub = fixtures_df.copy()\n",
    "#     df_sub['ht_score'] = scoreline\n",
    "#\n",
    "#     # b) Oneâ€hot encode the country column\n",
    "#     df_sub = pd.get_dummies(df_sub, columns=['country'], prefix='country')\n",
    "#\n",
    "#     # c) Locate the trained pipeline for this scoreline\n",
    "#     pattern     = os.path.join(MODEL_DIR, f\"trained_model_({repr(scoreline)},)_thr*.pkl\")\n",
    "#     model_files = glob.glob(pattern)\n",
    "#     if not model_files:\n",
    "#         print(f\"âš ï¸  No model for HT {scoreline} (looked for {pattern}), skipping.\")\n",
    "#         continue\n",
    "#\n",
    "#     md       = load(model_files[0])\n",
    "#     pipeline = md['pipeline']\n",
    "#     thresh   = md.get('threshold', 0.5)\n",
    "#\n",
    "#     # d) EXTRACT feature names *in the exact order* the model was trained on\n",
    "#     #    First try the final estimator; fall back to pipeline itself if supported.\n",
    "#     if hasattr(pipeline, 'feature_names_in_'):\n",
    "#         model_features = list(pipeline.feature_names_in_)\n",
    "#     else:\n",
    "#         clf = pipeline.named_steps.get('classifier', None)\n",
    "#         if clf is not None and hasattr(clf, 'feature_names_in_'):\n",
    "#             model_features = list(clf.feature_names_in_)\n",
    "#         else:\n",
    "#             raise ValueError(\n",
    "#                 \"Could not find `feature_names_in_` on your pipeline or classifier. \"\n",
    "#                 \"Please save the feature list when you train.\"\n",
    "#             )\n",
    "#\n",
    "#     # e) Reindex df_sub to exactly those columns, filling missing with 0\n",
    "#     X = df_sub.reindex(columns=model_features, fill_value=0)\n",
    "#\n",
    "#     # f) Predict probabilities (or labels) and apply threshold\n",
    "#     if hasattr(pipeline, \"predict_proba\"):\n",
    "#         proba = pipeline.predict_proba(X)[:, 1]\n",
    "#         df_sub['prediction_proba'] = proba\n",
    "#         df_sub['prediction']       = (proba >= thresh).astype(int)\n",
    "#     else:\n",
    "#         df_sub['prediction'] = pipeline.predict(X)\n",
    "#\n",
    "#     # g) Filter to positives\n",
    "#     positives = df_sub[df_sub['prediction'] == 1]\n",
    "#     if positives.empty:\n",
    "#         continue\n",
    "#\n",
    "#     # h) Build market/import metadata\n",
    "#     market_name    = f\"Over/Under {market_line} Goals\"\n",
    "#     selection_name = f\"Under {market_line} Goals\"\n",
    "#     provider       = f\"second_half_goal_{scoreline.replace('-', '_')}\"\n",
    "#     out_csv        = (\n",
    "#         rf\"C:\\Users\\leere\\OneDrive\\Desktop\\IMPORTS\"\n",
    "#         fr\"\\2H_GOAL_SCORELINE_{scoreline.replace('-', '_')}.csv\"\n",
    "#     )\n",
    "#\n",
    "#     # i) Write the import file\n",
    "#     fl.create_import_file(\n",
    "#         positives,\n",
    "#         out_csv,\n",
    "#         provider=provider,\n",
    "#         market_name=market_name,\n",
    "#         selection_name=selection_name\n",
    "#     )\n",
    "#\n",
    "#     print(\n",
    "#         f\"âœ… {len(positives)} positives for HT {scoreline} \"\n",
    "#         f\"(cut-off â‰¥ {thresh:.2f}) â†’ {out_csv}\"\n",
    "#     )\n"
   ],
   "id": "cae4d0bad6983f9a",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:12:13.104680Z",
     "start_time": "2025-05-30T07:12:13.099762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import pandas as pd\n",
    "#\n",
    "# # â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# IMPORT_DIR = r\"C:\\Users\\leere\\OneDrive\\Desktop\\IMPORTS\"\n",
    "# PATTERN    = os.path.join(IMPORT_DIR, \"2H_GOAL_SCORELINE_*.csv\")\n",
    "# OUT_PATH   = os.path.join(IMPORT_DIR, \"2H_GOAL_SCORELINE_ALL.csv\")\n",
    "#\n",
    "# # â”€â”€ FIND ALL MATCHING FILES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# file_list = glob.glob(PATTERN)\n",
    "# if not file_list:\n",
    "#     raise FileNotFoundError(f\"No files matched {PATTERN}\")\n",
    "#\n",
    "# # â”€â”€ READ & CONCATENATE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# df_list = [pd.read_csv(fp) for fp in file_list]\n",
    "# all_df  = pd.concat(df_list, ignore_index=True)\n",
    "#\n",
    "# # â”€â”€ SAVE MASTER FILE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# all_df.to_csv(OUT_PATH, index=False)\n",
    "# print(f\"âœ… Concatenated {len(file_list)} files into:\\n   {OUT_PATH}\")\n",
    "#\n",
    "# # â”€â”€ DELETE ORIGINAL FILES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# for fp in file_list:\n",
    "#     try:\n",
    "#         os.remove(fp)\n",
    "#         print(f\"ðŸ—‘  Deleted {fp}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"âš ï¸  Could not delete {fp}: {e}\")\n"
   ],
   "id": "82ee3d69591a3e53",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T07:12:13.445115Z",
     "start_time": "2025-05-30T07:12:13.113598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "\n",
    "# â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "MODEL_DIR   = r\"C:\\Users\\leere\\PycharmProjects\\Football_ML3\\Goals\\2H_goal\\ht_scoreline\\path_ht_score\\to\\save\\models\"\n",
    "fixtures_df = filtered_data.copy()   # must include at least 'home_team', 'away_team', 'country', etc.\n",
    "IMPORT_DIR  = r\"C:\\Users\\leere\\OneDrive\\Desktop\\IMPORTS\"\n",
    "OUT_PATH    = os.path.join(IMPORT_DIR, \"2H_GOAL_SCORELINE_ALL.csv\")\n",
    "\n",
    "market_map = {\n",
    "    \"0-0\": 0.5, \"0-1\": 1.5, \"1-0\": 1.5, \"1-1\": 1.5,\n",
    "    \"0-2\": 2.5, \"2-0\": 2.5, \"2-1\": 3.5, \"1-2\": 3.5,\n",
    "    \"3-0\": 3.5,\n",
    "}\n",
    "\n",
    "os.makedirs(IMPORT_DIR, exist_ok=True)\n",
    "\n",
    "# â”€â”€ COLLECT ALL POSITIVES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "all_positives = []\n",
    "\n",
    "for scoreline, market_line in market_map.items():\n",
    "    # a) prepare data\n",
    "    df_sub = fixtures_df.copy()\n",
    "    df_sub['ht_score'] = scoreline\n",
    "    df_sub = pd.get_dummies(df_sub, columns=['country'], prefix='country')\n",
    "\n",
    "    # b) load model\n",
    "    pattern     = os.path.join(MODEL_DIR, f\"trained_model_({repr(scoreline)},)_thr*.pkl\")\n",
    "    model_files = glob.glob(pattern)\n",
    "    if not model_files:\n",
    "        print(f\"âš ï¸  No model for HT {scoreline}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    md        = load(model_files[0])\n",
    "    pipeline  = md['pipeline']\n",
    "    threshold = md.get('threshold', 0.5)\n",
    "\n",
    "    # c) align features\n",
    "    if hasattr(pipeline, 'feature_names_in_'):\n",
    "        feat = list(pipeline.feature_names_in_)\n",
    "    else:\n",
    "        clf = pipeline.named_steps.get('classifier', None)\n",
    "        if clf and hasattr(clf, 'feature_names_in_'):\n",
    "            feat = list(clf.feature_names_in_)\n",
    "        else:\n",
    "            raise ValueError(\"Please save `feature_names_in_` when training your pipeline.\")\n",
    "\n",
    "    X = df_sub.reindex(columns=feat, fill_value=0)\n",
    "\n",
    "    # d) predict\n",
    "    if hasattr(pipeline, \"predict_proba\"):\n",
    "        proba = pipeline.predict_proba(X)[:,1]\n",
    "        mask  = proba >= threshold\n",
    "    else:\n",
    "        mask  = pipeline.predict(X).astype(bool)\n",
    "\n",
    "    positives = df_sub.loc[mask]\n",
    "    if positives.empty:\n",
    "        continue\n",
    "\n",
    "    # e) tag metadata\n",
    "    positives = positives.assign(\n",
    "        provider       = f\"second_half_goal_{scoreline.replace('-', '_')}\",\n",
    "        market_name    = f\"Over/Under {market_line} Goals\",\n",
    "        selection_name = f\"Under {market_line} Goals\"\n",
    "    )\n",
    "\n",
    "    all_positives.append(positives)\n",
    "    print(f\"âœ… {len(positives)} positives for HT {scoreline} (â‰¥ {threshold:.2f})\")\n",
    "\n",
    "# â”€â”€ WRITE SINGLE IMPORT FILE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if not all_positives:\n",
    "    print(\"âš ï¸  No positives found; nothing to write.\")\n",
    "else:\n",
    "    master_df = pd.concat(all_positives, ignore_index=True)\n",
    "\n",
    "    # replicate create_import_file logic in-line\n",
    "    match_series = master_df['home_team'] + ' v ' + master_df['away_team']\n",
    "    out_df = pd.DataFrame({\n",
    "        'EventName':     match_series,\n",
    "        'Provider':      master_df['provider'],\n",
    "        'MarketName':    master_df['market_name'],\n",
    "        'SelectionName': master_df['selection_name'],\n",
    "    })\n",
    "\n",
    "    out_df.to_csv(OUT_PATH, index=False)\n",
    "    print(f\"âœ… Single import file written with {len(out_df)} rows to:\\n   {OUT_PATH}\")\n"
   ],
   "id": "c48f6e55142d7b46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 8 positives for HT 0-0 (â‰¥ 0.72)\n",
      "âœ… 24 positives for HT 0-1 (â‰¥ 0.77)\n",
      "âœ… 29 positives for HT 1-0 (â‰¥ 0.78)\n",
      "âœ… 35 positives for HT 1-1 (â‰¥ 0.76)\n",
      "âš ï¸  No model for HT 0-2, skipping.\n",
      "âœ… 71 positives for HT 2-0 (â‰¥ 0.71)\n",
      "âœ… 66 positives for HT 2-1 (â‰¥ 0.73)\n",
      "âœ… 57 positives for HT 1-2 (â‰¥ 0.65)\n",
      "âœ… 73 positives for HT 3-0 (â‰¥ 0.62)\n",
      "âœ… Single import file written with 363 rows to:\n",
      "   C:\\Users\\leere\\OneDrive\\Desktop\\IMPORTS\\2H_GOAL_SCORELINE_ALL.csv\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
