{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-10T10:07:05.168538Z",
     "start_time": "2025-05-10T10:07:05.162394Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import function_library as fl\n",
    "from datetime import datetime\n"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:07:07.257369Z",
     "start_time": "2025-05-10T10:07:07.243408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Directory containing the CSV files\n",
    "directory = r\"C:\\Users\\leere\\PycharmProjects\\Football_ML3\\Goals\\Goals_v3\\best_model_metric_per_league_v3\"\n",
    "\n",
    "# List to collect each top row's data\n",
    "top_rows = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith(\"value_betting_top10\") and filename.endswith(\".csv\"):\n",
    "        league_name = filename.split(\"_\")[3]  # Extract league name from filename\n",
    "        file_path = os.path.join(directory, filename)\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            top_row = df.iloc[0]  # Get only the first row\n",
    "            top_rows.append({\n",
    "                'League': league_name,\n",
    "                'Model': top_row['model_name'],\n",
    "                'Strike Rate': top_row.get('strike_rate'),\n",
    "                'Params': top_row.get('model_params')\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "# Combine all results into one DataFrame\n",
    "results_df = pd.DataFrame(top_rows)\n",
    "\n",
    "# Save or display results\n",
    "#results_df.to_csv(\"top_row_model_params.csv\", index=False)\n",
    "\n"
   ],
   "id": "fce1a11317aadeba",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:07:08.760982Z",
     "start_time": "2025-05-10T10:07:08.749820Z"
    }
   },
   "cell_type": "code",
   "source": "results_df",
   "id": "4d8e688853c111c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      League Model  Strike Rate  \\\n",
       "0  ('Pol1',)   MLP       0.5655   \n",
       "\n",
       "                                              Params  \n",
       "0  {'alpha': 0.0001, 'hidden_layer_sizes': (100, ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>League</th>\n",
       "      <th>Model</th>\n",
       "      <th>Strike Rate</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('Pol1',)</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.5655</td>\n",
       "      <td>{'alpha': 0.0001, 'hidden_layer_sizes': (100, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:07:12.477897Z",
     "start_time": "2025-05-10T10:07:12.461618Z"
    }
   },
   "cell_type": "code",
   "source": "features = ['round', 'home_team_place_total', 'home_team_place_home', 'away_team_place_total', 'away_team_place_away', 'home_odds', 'draw_odds', 'away_odds', 'over_25_odds', 'under_25_odds', 'elo_home', 'elo_away', 'form_home', 'form_away', 'home_Overall_Rolling_GoalsScored_Mean', 'home_Overall_Rolling_GoalsScored_Std', 'home_Overall_Rolling_GoalsScored_Mean_Short', 'home_Overall_Momentum_GoalsScored', 'home_Overall_Trend_Slope_GoalsScored', 'home_Overall_Rolling_FirstHalfGoalsScored_Mean', 'home_Overall_Rolling_FirstHalfGoalsScored_Std', 'home_Overall_Rolling_FirstHalfGoalsScored_Mean_Short', 'home_Overall_Momentum_FirstHalfGoalsScored', 'home_Overall_Trend_Slope_FirstHalfGoalsScored', 'home_Overall_Rolling_Shots_Mean', 'home_Overall_Rolling_Shots_Std', 'home_Overall_Rolling_Shots_Mean_Short', 'home_Overall_Momentum_Shots', 'home_Overall_Trend_Slope_Shots', 'home_Overall_Rolling_Shots_1h_Mean', 'home_Overall_Rolling_Shots_1h_Std', 'home_Overall_Rolling_Shots_1h_Mean_Short', 'home_Overall_Momentum_Shots_1h', 'home_Overall_Trend_Slope_Shots_1h', 'home_Overall_Rolling_Corners_Mean', 'home_Overall_Rolling_Corners_Std', 'home_Overall_Rolling_Corners_Mean_Short', 'home_Overall_Momentum_Corners', 'home_Overall_Trend_Slope_Corners', 'home_Overall_Rolling_Corners_1h_Mean', 'home_Overall_Rolling_Corners_1h_Std', 'home_Overall_Rolling_Corners_1h_Mean_Short', 'home_Overall_Momentum_Corners_1h', 'home_Overall_Trend_Slope_Corners_1h', 'home_Overall_Rolling_ShotsOnTarget_Mean', 'home_Overall_Rolling_ShotsOnTarget_Std', 'home_Overall_Rolling_ShotsOnTarget_Mean_Short', 'home_Overall_Momentum_ShotsOnTarget', 'home_Overall_Trend_Slope_ShotsOnTarget', 'home_Overall_Rolling_ShotsOnTarget_1h_Mean', 'home_Overall_Rolling_ShotsOnTarget_1h_Std', 'home_Overall_Rolling_ShotsOnTarget_1h_Mean_Short', 'home_Overall_Momentum_ShotsOnTarget_1h', 'home_Overall_Trend_Slope_ShotsOnTarget_1h', 'home_Rolling_GoalsScored_Mean', 'home_Rolling_GoalsScored_Std', 'home_Rolling_GoalsScored_Mean_Short', 'home_Momentum_GoalsScored', 'home_Trend_Slope_GoalsScored', 'home_Rolling_FirstHalfGoalsScored_Mean', 'home_Rolling_FirstHalfGoalsScored_Std', 'home_Rolling_FirstHalfGoalsScored_Mean_Short', 'home_Momentum_FirstHalfGoalsScored', 'home_Trend_Slope_FirstHalfGoalsScored', 'home_Rolling_Shots_Mean', 'home_Rolling_Shots_Std', 'home_Rolling_Shots_Mean_Short', 'home_Momentum_Shots', 'home_Trend_Slope_Shots', 'home_Rolling_Shots_1h_Mean', 'home_Rolling_Shots_1h_Std', 'home_Rolling_Shots_1h_Mean_Short', 'home_Momentum_Shots_1h', 'home_Trend_Slope_Shots_1h', 'home_Rolling_Corners_Mean', 'home_Rolling_Corners_Std', 'home_Rolling_Corners_Mean_Short', 'home_Momentum_Corners', 'home_Trend_Slope_Corners', 'home_Rolling_Corners_1h_Mean', 'home_Rolling_Corners_1h_Std', 'home_Rolling_Corners_1h_Mean_Short', 'home_Momentum_Corners_1h', 'home_Trend_Slope_Corners_1h', 'home_Rolling_ShotsOnTarget_Mean', 'home_Rolling_ShotsOnTarget_Std', 'home_Rolling_ShotsOnTarget_Mean_Short', 'home_Momentum_ShotsOnTarget', 'home_Trend_Slope_ShotsOnTarget', 'home_Rolling_ShotsOnTarget_1h_Mean', 'home_Rolling_ShotsOnTarget_1h_Std', 'home_Rolling_ShotsOnTarget_1h_Mean_Short', 'home_Momentum_ShotsOnTarget_1h', 'home_Trend_Slope_ShotsOnTarget_1h', 'home_Overall_Percent_Over_1.5', 'home_Overall_Rolling5_Percent_Over_1.5', 'home_Percent_Over_1.5', 'home_Rolling5_Percent_Over_1.5', 'home_Overall_Percent_Over_2.5', 'home_Overall_Rolling5_Percent_Over_2.5', 'home_Percent_Over_2.5', 'home_Rolling5_Percent_Over_2.5', 'home_Overall_Percent_Over_3.5', 'home_Overall_Rolling5_Percent_Over_3.5', 'home_Percent_Over_3.5', 'home_Rolling5_Percent_Over_3.5', 'home_TeamPct_Over_0.5', 'home_TeamPct_Over_1.5', 'home_TeamPct_Over_2.5', 'home_TeamPct_Over_3.5', 'home_CornersPct_Over_3.5', 'home_CornersRolling5Pct_Over_3.5', 'home_CornersPct_Over_4.5', 'home_CornersRolling5Pct_Over_4.5', 'home_CornersPct_Over_5.5', 'home_CornersRolling5Pct_Over_5.5', 'home_CornersPct_Over_6.5', 'home_CornersRolling5Pct_Over_6.5', 'home_SeasonPct_Over_9.5', 'home_Rolling5Pct_Over_9.5', 'home_SeasonPct_Over_10.5', 'home_Rolling5Pct_Over_10.5', 'home_SeasonPct_Over_11.5', 'home_Rolling5Pct_Over_11.5', 'away_Overall_Rolling_GoalsScored_Mean', 'away_Overall_Rolling_GoalsScored_Std', 'away_Overall_Rolling_GoalsScored_Mean_Short', 'away_Overall_Momentum_GoalsScored', 'away_Overall_Trend_Slope_GoalsScored', 'away_Overall_Rolling_FirstHalfGoalsScored_Mean', 'away_Overall_Rolling_FirstHalfGoalsScored_Std', 'away_Overall_Rolling_FirstHalfGoalsScored_Mean_Short', 'away_Overall_Momentum_FirstHalfGoalsScored', 'away_Overall_Trend_Slope_FirstHalfGoalsScored', 'away_Overall_Rolling_Shots_Mean', 'away_Overall_Rolling_Shots_Std', 'away_Overall_Rolling_Shots_Mean_Short', 'away_Overall_Momentum_Shots', 'away_Overall_Trend_Slope_Shots', 'away_Overall_Rolling_Shots_1h_Mean', 'away_Overall_Rolling_Shots_1h_Std', 'away_Overall_Rolling_Shots_1h_Mean_Short', 'away_Overall_Momentum_Shots_1h', 'away_Overall_Trend_Slope_Shots_1h', 'away_Overall_Rolling_Corners_Mean', 'away_Overall_Rolling_Corners_Std', 'away_Overall_Rolling_Corners_Mean_Short', 'away_Overall_Momentum_Corners', 'away_Overall_Trend_Slope_Corners', 'away_Overall_Rolling_Corners_1h_Mean', 'away_Overall_Rolling_Corners_1h_Std', 'away_Overall_Rolling_Corners_1h_Mean_Short', 'away_Overall_Momentum_Corners_1h', 'away_Overall_Trend_Slope_Corners_1h', 'away_Overall_Rolling_ShotsOnTarget_Mean', 'away_Overall_Rolling_ShotsOnTarget_Std', 'away_Overall_Rolling_ShotsOnTarget_Mean_Short', 'away_Overall_Momentum_ShotsOnTarget', 'away_Overall_Trend_Slope_ShotsOnTarget', 'away_Overall_Rolling_ShotsOnTarget_1h_Mean', 'away_Overall_Rolling_ShotsOnTarget_1h_Std', 'away_Overall_Rolling_ShotsOnTarget_1h_Mean_Short', 'away_Overall_Momentum_ShotsOnTarget_1h', 'away_Overall_Trend_Slope_ShotsOnTarget_1h', 'away_Rolling_GoalsScored_Mean', 'away_Rolling_GoalsScored_Std', 'away_Rolling_GoalsScored_Mean_Short', 'away_Momentum_GoalsScored', 'away_Trend_Slope_GoalsScored', 'away_Rolling_FirstHalfGoalsScored_Mean', 'away_Rolling_FirstHalfGoalsScored_Std', 'away_Rolling_FirstHalfGoalsScored_Mean_Short', 'away_Momentum_FirstHalfGoalsScored', 'away_Trend_Slope_FirstHalfGoalsScored', 'away_Rolling_Shots_Mean', 'away_Rolling_Shots_Std', 'away_Rolling_Shots_Mean_Short', 'away_Momentum_Shots', 'away_Trend_Slope_Shots', 'away_Rolling_Shots_1h_Mean', 'away_Rolling_Shots_1h_Std', 'away_Rolling_Shots_1h_Mean_Short', 'away_Momentum_Shots_1h', 'away_Trend_Slope_Shots_1h', 'away_Rolling_Corners_Mean', 'away_Rolling_Corners_Std', 'away_Rolling_Corners_Mean_Short', 'away_Momentum_Corners', 'away_Trend_Slope_Corners', 'away_Rolling_Corners_1h_Mean', 'away_Rolling_Corners_1h_Std', 'away_Rolling_Corners_1h_Mean_Short', 'away_Momentum_Corners_1h', 'away_Trend_Slope_Corners_1h', 'away_Rolling_ShotsOnTarget_Mean', 'away_Rolling_ShotsOnTarget_Std', 'away_Rolling_ShotsOnTarget_Mean_Short', 'away_Momentum_ShotsOnTarget', 'away_Trend_Slope_ShotsOnTarget', 'away_Rolling_ShotsOnTarget_1h_Mean', 'away_Rolling_ShotsOnTarget_1h_Std', 'away_Rolling_ShotsOnTarget_1h_Mean_Short', 'away_Momentum_ShotsOnTarget_1h', 'away_Trend_Slope_ShotsOnTarget_1h', 'away_Overall_Percent_Over_1.5', 'away_Overall_Rolling5_Percent_Over_1.5', 'away_Percent_Over_1.5', 'away_Rolling5_Percent_Over_1.5', 'away_Overall_Percent_Over_2.5', 'away_Overall_Rolling5_Percent_Over_2.5', 'away_Percent_Over_2.5', 'away_Rolling5_Percent_Over_2.5', 'away_Overall_Percent_Over_3.5', 'away_Overall_Rolling5_Percent_Over_3.5', 'away_Percent_Over_3.5', 'away_Rolling5_Percent_Over_3.5', 'away_TeamPct_Over_0.5', 'away_TeamPct_Over_1.5', 'away_TeamPct_Over_2.5', 'away_TeamPct_Over_3.5', 'away_CornersPct_Over_3.5', 'away_CornersRolling5Pct_Over_3.5', 'away_CornersPct_Over_4.5', 'away_CornersRolling5Pct_Over_4.5', 'away_CornersPct_Over_5.5', 'away_CornersRolling5Pct_Over_5.5', 'away_CornersPct_Over_6.5', 'away_CornersRolling5Pct_Over_6.5', 'away_SeasonPct_Over_9.5', 'away_Rolling5Pct_Over_9.5', 'away_SeasonPct_Over_10.5', 'away_Rolling5Pct_Over_10.5', 'away_SeasonPct_Over_11.5', 'away_Rolling5Pct_Over_11.5', 'country_Arg1', 'country_Aus1', 'country_Aus2', 'country_Aut1', 'country_Bel1', 'country_Bra1', 'country_Bul1', 'country_Chi1', 'country_Chl1', 'country_Cro1', 'country_Czh1', 'country_Den1', 'country_Eng1', 'country_Eng2', 'country_Eng3', 'country_Eng4', 'country_Fra1', 'country_Fra2', 'country_Ger1', 'country_Ger2', 'country_Ger3', 'country_Gre1', 'country_Hun1', 'country_Ice1', 'country_Ire1', 'country_Isr1', 'country_Ita1', 'country_Ita2', 'country_Jap1', 'country_Jap2', 'country_Kor1', 'country_Mex1', 'country_Ned1', 'country_Ned2', 'country_Nor1', 'country_Pol1', 'country_Por1', 'country_Rom1', 'country_Sco1', 'country_Sco2', 'country_Slk1', 'country_Slo1', 'country_Spa1', 'country_Spa2', 'country_Swe1', 'country_Swe2', 'country_Swi1', 'country_Swi2', 'country_Tur1', 'country_Tur2', 'country_USA1']",
   "id": "c91fc6401176381e",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:07:33.541451Z",
     "start_time": "2025-05-10T10:07:24.595152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pre_prepared_data(file_path):\n",
    "    data = pd.read_csv(file_path,\n",
    "                       low_memory=False)\n",
    "    # Convert 'date' column to datetime object\n",
    "    data['date'] = pd.to_datetime(data['date'], format=\"%Y-%m-%d\", errors='coerce')\n",
    "    data = data.sort_values(by='date')\n",
    "\n",
    "    # Convert today's date to a pandas Timestamp for compatibility.\n",
    "    today = pd.Timestamp(datetime.today().date())\n",
    "    data = data[data['date'] <= today]\n",
    "\n",
    "    # Clean up and finalise the match-level DataFrame\n",
    "    data.dropna(inplace=True)\n",
    "    data['total_goals'] = data['home_goals_ft'] + data['away_goals_ft']\n",
    "    data['target'] = data['total_goals'].apply(lambda x: 1 if x > 2.5 else 0)\n",
    "    return data\n",
    "matches = pre_prepared_data(r\"/engineered_master_data_ALL_2017+.csv\")\n",
    "\n",
    "# Process each league separately\n",
    "leagues = matches[['country']].drop_duplicates().apply(tuple, axis=1)"
   ],
   "id": "d7394273217bc600",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:07:33.577354Z",
     "start_time": "2025-05-10T10:07:33.550690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "matches_filtered = matches[matches['country']=='Pol1']\n",
    "data =matches_filtered.copy()\n",
    "#matches_filtered"
   ],
   "id": "e6ab350b9509433e",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:07:33.645361Z",
     "start_time": "2025-05-10T10:07:33.628985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def replicate_run_from_csv_row(data, features, row, stake=1.0):\n",
    "    \"\"\"\n",
    "    Simulate the exact value-bet backtest, including scaling, for a saved model configuration.\n",
    "\n",
    "    - Splits data chronologically: first 80% train, last 20% test\n",
    "    - Builds pipeline: StandardScaler -> base model\n",
    "    - Fits and calibrates via Platt scaling\n",
    "    - On test, computes model-implied odds = 1/prob\n",
    "    - Identifies value bets where model_odds < market odds\n",
    "    - Stakes `stake` units per bet, computes profit\n",
    "    - Returns metrics: num_bets, total_profit, roi, strike_rate, p-value\n",
    "    \"\"\"\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "    # Extract model info\n",
    "    import ast\n",
    "    model_name = row['Model']\n",
    "    params = ast.literal_eval(row['Params']) if isinstance(row['Params'], str) else row['Params']\n",
    "    odds_feature = 'over_25_odds'\n",
    "\n",
    "    # Chronological split\n",
    "    split_idx = int(len(data) * 0.8)\n",
    "    train_df = data.iloc[:split_idx]\n",
    "    test_df = data.iloc[split_idx:].copy()\n",
    "    X_train, y_train = train_df[features], train_df['target']\n",
    "    X_test, y_test = test_df[features], test_df['target']\n",
    "\n",
    "    # Instantiate base model\n",
    "    if model_name.lower().startswith('mlp'):\n",
    "        from sklearn.neural_network import MLPClassifier\n",
    "        base = MLPClassifier(random_state=42, **params)\n",
    "    elif model_name.lower().startswith('xgboost'):\n",
    "        from xgboost import XGBClassifier\n",
    "        base = XGBClassifier(random_state=42, eval_metric='logloss', **params)\n",
    "    elif 'forest' in model_name.lower():\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        base = RandomForestClassifier(random_state=42, **params)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "\n",
    "    # Build and fit scaling pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model',  base)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Calibrate probabilities\n",
    "    calibrated = CalibratedClassifierCV(pipe, method='sigmoid', cv='prefit')\n",
    "    calibrated.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and compute odds\n",
    "    probs = calibrated.predict_proba(X_test)[:, 1]\n",
    "    test_df['model_odds'] = 1/(probs + 1e-12)\n",
    "\n",
    "    # Identify value bets\n",
    "    bets = test_df.loc[test_df['model_odds'] < test_df[odds_feature]].copy()\n",
    "    # Compute profit per bet\n",
    "    bets['profit'] = bets.apply(\n",
    "        lambda r: (r[odds_feature] - 1) * stake if r['target'] == 1 else -stake,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Aggregate metrics\n",
    "    num_bets = len(bets)\n",
    "    total_profit = bets['profit'].sum()\n",
    "    roi = total_profit / num_bets if num_bets > 0 else 0\n",
    "    strike_rate = bets['target'].sum() / num_bets if num_bets > 0 else 0\n",
    "    from scipy import stats\n",
    "    pvalue = None\n",
    "    if num_bets > 1:\n",
    "        _, pvalue = stats.ttest_1samp(bets['profit'], 0)\n",
    "\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'model_params': params,\n",
    "        'num_bets': num_bets,\n",
    "        'total_profit': round(total_profit, 4),\n",
    "        'roi': round(roi, 4),\n",
    "        'strike_rate': round(strike_rate, 4),\n",
    "        'pvalue': round(pvalue, 4) if pvalue is not None else None\n",
    "    }\n",
    "\n",
    "\n",
    "# def replicate_run_from_csv_row(data, features, row, stake=1.0):\n",
    "#     \"\"\"\n",
    "#     Simulate the exact value-bet backtest defined in training, for a single saved model configuration.\n",
    "#\n",
    "#     - Trains on the first 80% of `data` (time-ordered)\n",
    "#     - Calibrates probabilities via sigmoid Platt scaling\n",
    "#     - On the test split (last 20%), computes model-implied odds = 1/prob\n",
    "#     - Identifies \"value\" bets where model_odds < market odds (`over_25_odds`)\n",
    "#     - Stakes `stake` units on each value bet\n",
    "#     - Calculates per-bet profit: (odds-1)*stake on wins, -stake on losses\n",
    "#     - Returns a dict including:\n",
    "#         * number of bets\n",
    "#         * total profit\n",
    "#         * ROI (profit per bet)\n",
    "#         * strike rate\n",
    "#         * p-value (one-sample t-test of profits vs 0)\n",
    "#         * model_class and params for replication\n",
    "#     \"\"\"\n",
    "#     import ast\n",
    "#     from sklearn.calibration import CalibratedClassifierCV\n",
    "#\n",
    "#     # 1) extract model info\n",
    "#     model_name = row['Model']\n",
    "#     params = ast.literal_eval(row['Params']) if isinstance(row['Params'], str) else row['Params']\n",
    "#     odds_feature = 'over_25_odds'\n",
    "#\n",
    "#     # 2) split data chronologically\n",
    "#     split_idx = int(len(data)*0.8)\n",
    "#     train_df = data.iloc[:split_idx]\n",
    "#     test_df  = data.iloc[split_idx:].copy()\n",
    "#\n",
    "#     X_train = train_df[features]\n",
    "#     y_train = train_df['target']\n",
    "#     X_test  = test_df[features]\n",
    "#     y_test  = test_df['target']\n",
    "#\n",
    "#     # 3) instantiate model\n",
    "#     if model_name.lower().startswith('mlp'):\n",
    "#         from sklearn.neural_network import MLPClassifier\n",
    "#         base = MLPClassifier(random_state=42, **params)\n",
    "#     elif model_name.lower().startswith('xgboost'):\n",
    "#         from xgboost import XGBClassifier\n",
    "#         base = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', **params)\n",
    "#     elif 'forest' in model_name.lower():\n",
    "#         from sklearn.ensemble import RandomForestClassifier\n",
    "#         base = RandomForestClassifier(random_state=42, **params)\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "#\n",
    "#     # 4) calibrate on train\n",
    "#     base.fit(X_train, y_train)\n",
    "#     calibrated = CalibratedClassifierCV(base, method='sigmoid', cv='prefit')\n",
    "#     calibrated.fit(X_train, y_train)\n",
    "#\n",
    "#     # 5) predict probs on test\n",
    "#     proba = calibrated.predict_proba(X_test)[:,1]\n",
    "#     test_df['model_prob'] = proba\n",
    "#     test_df['model_odds'] = 1/(proba+1e-12)\n",
    "#\n",
    "#     # 6) find value bets\n",
    "#     bets = test_df.loc[test_df['model_odds'] < test_df[odds_feature]].copy()\n",
    "#\n",
    "#     # 7) simulate stakes and profit\n",
    "#     # profit = (market_odds - 1)*stake if win else -stake\n",
    "#     bets['profit'] = bets.apply(\n",
    "#         lambda r: (r[odds_feature]-1)*stake if r['target']==1 else -stake,\n",
    "#         axis=1\n",
    "#     )\n",
    "#     num_bets = len(bets)\n",
    "#     total_profit = bets['profit'].sum()\n",
    "#     roi = total_profit/num_bets if num_bets>0 else 0\n",
    "#     wins = int(bets['target'].sum())\n",
    "#     strike_rate = wins/num_bets if num_bets>0 else 0\n",
    "#\n",
    "#     # 8) p-value\n",
    "#     from scipy import stats\n",
    "#     if num_bets>1:\n",
    "#         _, pvalue = stats.ttest_1samp(bets['profit'], 0)\n",
    "#     else:\n",
    "#         pvalue = None\n",
    "#\n",
    "#     # 9) return metrics\n",
    "#     return {\n",
    "#         'model_name': model_name,\n",
    "#         'model_params': params,\n",
    "#         'num_bets': num_bets,\n",
    "#         'total_profit': round(total_profit,4),\n",
    "#         'roi': round(roi,4),\n",
    "#         'strike_rate': round(strike_rate,4),\n",
    "#         'pvalue': round(pvalue,4) if pvalue is not None else None\n",
    "#     }\n",
    "#\n"
   ],
   "id": "63e697756e8b41a2",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:07:42.003576Z",
     "start_time": "2025-05-10T10:07:37.771847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "row = results_df.iloc[0]\n",
    "metrics = replicate_run_from_csv_row(data, features, row)\n",
    "print(metrics)"
   ],
   "id": "2a811571cbe416ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'MLP', 'model_params': {'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'max_iter': 1000}, 'num_bets': 168, 'total_profit': np.float64(12.76), 'roi': np.float64(0.076), 'strike_rate': np.float64(0.5655), 'pvalue': np.float64(0.3114)}\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:07:48.113068Z",
     "start_time": "2025-05-10T10:07:48.099599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import ast\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def train_and_save_model(data, features, row, output_dir):\n",
    "    \"\"\"\n",
    "    Trains and saves a calibrated model pipeline for a given league configuration.\n",
    "\n",
    "    - Splits data 80% train / 20% test chronologically\n",
    "    - Instantiates model from row['Model'] and row['Params']\n",
    "    - Fits model on train set and calibrates probabilities\n",
    "    - Saves the calibrated pipeline to a pickle named by league and model\n",
    "\n",
    "    Returns the path to the saved pickle.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Extract configuration\n",
    "    raw_league = row.get('League', 'unknown')\n",
    "    # Normalize league format: handle tuples like ('Arg1',)\n",
    "    if isinstance(raw_league, (tuple, list)):\n",
    "        league = raw_league[0]\n",
    "    else:\n",
    "        try:\n",
    "            parsed = ast.literal_eval(raw_league) if isinstance(raw_league, str) else raw_league\n",
    "            league = parsed[0] if isinstance(parsed, (tuple, list)) else str(parsed)\n",
    "        except Exception:\n",
    "            league = str(raw_league)\n",
    "\n",
    "    model_name = row['Model']\n",
    "    params     = ast.literal_eval(row['Params']) if isinstance(row['Params'], str) else row['Params']\n",
    "    fname      = f\"{league}_{model_name}.pkl\"\n",
    "    path       = os.path.join(output_dir, fname)\n",
    "\n",
    "    # Chronological split\n",
    "    split_idx = int(len(data) * 0.8)\n",
    "    train_df = data.iloc[:split_idx]\n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df['target']\n",
    "\n",
    "    # Instantiate base estimator\n",
    "    if model_name.lower().startswith('mlp'):\n",
    "        base = MLPClassifier(random_state=42, **params)\n",
    "    elif model_name.lower().startswith('xgboost'):\n",
    "        base = XGBClassifier(random_state=42, eval_metric='logloss', **params)\n",
    "    elif 'forest' in model_name.lower():\n",
    "        base = RandomForestClassifier(random_state=42, **params)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "\n",
    "    # Build full pipeline: scaler -> base -> calibrator\n",
    "    pipeline = ImbPipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', base)\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    calibrated = CalibratedClassifierCV(pipeline, method='sigmoid', cv='prefit')\n",
    "    calibrated.fit(X_train, y_train)\n",
    "\n",
    "    # Save pipeline\n",
    "    joblib.dump(calibrated, path)\n",
    "    print(f\"Saved calibrated model pipeline to {path}\")\n",
    "    return path\n",
    "\n",
    "\n",
    "def train_and_save_all_league_models(data, features, results_df, output_dir):\n",
    "    \"\"\"\n",
    "    Iterates over each row in results_df, filters data for that league, trains and saves the model.\n",
    "\n",
    "    Returns a list of filepaths for all saved models.\n",
    "    \"\"\"\n",
    "    saved_paths = []\n",
    "    for _, row in results_df.iterrows():\n",
    "        raw_league = row.get('League', 'unknown')\n",
    "        # Normalize league format\n",
    "        if isinstance(raw_league, (tuple, list)):\n",
    "            league = raw_league[0]\n",
    "        else:\n",
    "            try:\n",
    "                parsed = ast.literal_eval(raw_league) if isinstance(raw_league, str) else raw_league\n",
    "                league = parsed[0] if isinstance(parsed, (tuple, list)) else str(parsed)\n",
    "            except Exception:\n",
    "                league = str(raw_league)\n",
    "\n",
    "        league_df = data[data['country'] == league]\n",
    "        if league_df.empty:\n",
    "            print(f\"No data for league {league}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        path = train_and_save_model(league_df, features, row, output_dir)\n",
    "        saved_paths.append(path)\n",
    "    return saved_paths\n"
   ],
   "id": "4c48feccaa62e638",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:07:55.324668Z",
     "start_time": "2025-05-10T10:07:50.192365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_directory = r\"path\\to\\save\\models\"\n",
    "saved_model_files = train_and_save_all_league_models(matches, features, results_df, output_directory)\n",
    "#print(\"Saved model files:\", saved_model_files)"
   ],
   "id": "7e32eb553596be98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved calibrated model pipeline to path\\to\\save\\models\\Pol1_MLP.pkl\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:08:02.344875Z",
     "start_time": "2025-05-10T10:08:02.332991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_and_test_model(pkl_path, matches, features, odds_feature='over_25_odds', stake=1.0):\n",
    "    \"\"\"\n",
    "    Loads a saved calibrated model pipeline from `pkl_path`, applies it to the last 20% of `data`,\n",
    "    simulates the same value-bet logic, and prints summary metrics to verify correctness.\n",
    "\n",
    "    Args:\n",
    "      pkl_path (str): path to the saved .pkl model file\n",
    "      data (pd.DataFrame): full dataset including features, 'target', and odds_feature\n",
    "      features (list): list of feature column names\n",
    "      odds_feature (str): column name for market odds\n",
    "      stake (float): units staked per value bet\n",
    "\n",
    "    Returns:\n",
    "      pd.DataFrame of individual bet results and a summary dict of metrics\n",
    "    \"\"\"\n",
    "    # Load pipeline\n",
    "    calibrated = joblib.load(pkl_path)\n",
    "    # Prepare test split\n",
    "    split_idx = int(len(data) * 0.8)\n",
    "    test_df = data.iloc[split_idx:].copy()\n",
    "    X_test = test_df[features]\n",
    "    y_test = test_df['target']\n",
    "    # Predict probabilities and implied odds\n",
    "    proba = calibrated.predict_proba(X_test)[:,1]\n",
    "    test_df['model_prob'] = proba\n",
    "    test_df['model_odds'] = 1/(proba + 1e-12)\n",
    "    # Identify value bets\n",
    "    bets = test_df.loc[test_df['model_odds'] < test_df[odds_feature]].copy()\n",
    "    # Simulate profit\n",
    "    bets['profit'] = bets.apply(\n",
    "        lambda r: (r[odds_feature] - 1) * stake if r['target']==1 else -stake,\n",
    "        axis=1\n",
    "    )\n",
    "    # Compute summary metrics\n",
    "    num_bets = len(bets)\n",
    "    total_profit = bets['profit'].sum()\n",
    "    roi = total_profit / num_bets if num_bets>0 else 0\n",
    "    strike_rate = bets['target'].sum() / num_bets if num_bets>0 else 0\n",
    "    from scipy import stats\n",
    "    pvalue = None\n",
    "    if num_bets > 1:\n",
    "        _, pvalue = stats.ttest_1samp(bets['profit'], 0)\n",
    "    summary = {\n",
    "        'model_file': pkl_path,\n",
    "        'num_bets': num_bets,\n",
    "        'total_profit': round(total_profit,4),\n",
    "        'roi': round(roi,4),\n",
    "        'strike_rate': round(strike_rate,4),\n",
    "        'pvalue': round(pvalue,4) if pvalue is not None else None\n",
    "    }\n",
    "    print(\"Test Summary:\")\n",
    "    for k,v in summary.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    return bets, summary\n",
    "\n"
   ],
   "id": "97ae462ba431b60c",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:08:22.061197Z",
     "start_time": "2025-05-10T10:08:22.026161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bets_df, metrics = load_and_test_model(\n",
    "    r\"/Goals/Goals_v3/path/to/save/models/Pol1_MLP.pkl\",\n",
    "    matches_filtered,\n",
    "    features\n",
    ")\n"
   ],
   "id": "dca5827788ad7e58",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Summary:\n",
      "  model_file: C:\\Users\\leere\\PycharmProjects\\Football_ML3\\Goals\\Goals_v3\\path\\to\\save\\models\\Pol1_MLP.pkl\n",
      "  num_bets: 168\n",
      "  total_profit: 12.76\n",
      "  roi: 0.076\n",
      "  strike_rate: 0.5655\n",
      "  pvalue: 0.3114\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:08:26.621845Z",
     "start_time": "2025-05-10T10:08:26.609158Z"
    }
   },
   "cell_type": "code",
   "source": "results_df",
   "id": "c5c7917c0d2c6ba4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      League Model  Strike Rate  \\\n",
       "0  ('Pol1',)   MLP       0.5655   \n",
       "\n",
       "                                              Params  \n",
       "0  {'alpha': 0.0001, 'hidden_layer_sizes': (100, ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>League</th>\n",
       "      <th>Model</th>\n",
       "      <th>Strike Rate</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('Pol1',)</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.5655</td>\n",
       "      <td>{'alpha': 0.0001, 'hidden_layer_sizes': (100, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
